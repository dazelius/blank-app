import streamlit as st
import gspread
from google.oauth2 import service_account
import re
import difflib
import json
from datetime import datetime
import os
import pandas as pd
import streamlit as st
import html
import requests
from PIL import Image
from io import BytesIO

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="í…ìŠ¤íŠ¸ í•„í„°",
    page_icon="âš ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': "ë¬¸ì¥ì˜ ìœ„í—˜ë„ë¥¼ ë¶„ì„í•´ë“œë¦½ë‹ˆë‹¤."
    }
)

# Open Graph ë©”íƒ€ íƒœê·¸ ìˆ˜ì •
st.markdown('''
    <head>
        <title>í…ìŠ¤íŠ¸ í•„í„°</title>
        <meta property="og:title" content="í…ìŠ¤íŠ¸ í•„í„°"/>
        <meta property="og:description" content="í…ìŠ¤íŠ¸ í•„í„°"/>
        <meta property="og:image" content="í…ìŠ¤íŠ¸ í•„í„°"/>
    </head>''', unsafe_allow_html=True)

# CSS ìŠ¤íƒ€ì¼ ì—…ë°ì´íŠ¸
st.markdown("""
<style>
    /* ë‹¤í¬ëª¨ë“œ ê¸°ë³¸ ë°°ê²½ ë° í…ìŠ¤íŠ¸ ìƒ‰ìƒ */
    .stApp {
        background-color: #1E1E1E;
        color: #E0E0E0;
    }
    
    /* ë©”ì¸ íƒ€ì´í‹€ ìŠ¤íƒ€ì¼ */
    .main-title {
        text-align: center;
        padding: 1.5rem;
        background: linear-gradient(135deg, #434343 0%, #000000 100%);
        color: #E0E0E0;
        border-radius: 15px;
        margin-bottom: 2rem;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
    }
    
    /* ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .analysis-card {
        background: #2D2D2D;
        padding: 1.5rem;
        border-radius: 15px;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
        margin-bottom: 1rem;
        color: #E0E0E0;
    }
    
    /* ìœ„í—˜ë„ ë¯¸í„° ìŠ¤íƒ€ì¼ */
    .danger-meter {
        text-align: center;
        padding: 2rem;
        margin: 1rem 0;
        border-radius: 15px;
        background: #2D2D2D;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
    }
    
    /* ì…ë ¥ í•„ë“œ ìŠ¤íƒ€ì¼ */
    .stTextInput>div>div>input {
        background-color: #3D3D3D;
        color: #E0E0E0;
        border-color: #4D4D4D;
    }
    
    .stTextArea>div>div>textarea {
        background-color: #3D3D3D;
        color: #E0E0E0;
        border-color: #4D4D4D;
    }
    
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton>button {
        background: linear-gradient(to right, #434343 0%, #000000 100%);
        color: #E0E0E0;
        border: none;
        padding: 0.5rem 1rem;
        border-radius: 10px;
        font-weight: 600;
        transition: transform 0.2s;
    }
    
    .stButton>button:hover {
        transform: translateY(-2px);
        background: linear-gradient(to right, #4a4a4a 0%, #1a1a1a 100%);
    }
    
    /* íƒ­ ìŠ¤íƒ€ì¼ */
    .stTabs [data-baseweb="tab-list"] {
        background-color: #2D2D2D;
        border-radius: 15px;
    }
    
    .stTabs [data-baseweb="tab"] {
        color: #E0E0E0;
    }
    
    /* ë§í¬ ìŠ¤íƒ€ì¼ */
    a {
        color: #00B4DB;
        text-decoration: none;
    }
    
    a:hover {
        text-decoration: underline;
        color: #00D4FF;
    }
    
    /* ìœ„í—˜ë„ ë ˆë²¨ ìƒ‰ìƒ */
    .danger-level-low {
        color: #00E676;
    }
    
    .danger-level-medium {
        color: #FFD700;
    }
    
    .danger-level-high {
        color: #FF5252;
    }
    
    /* ì•Œë¦¼ ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
    .stAlert {
        background-color: #2D2D2D;
        color: #E0E0E0;
        border-radius: 10px;
    }
    /* ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìŠ¤íƒ€ì¼ */
    .database-table {
        margin-top: 2rem;
        padding: 1rem;
        background: #2D2D2D;
        border-radius: 15px;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
    }
    
    .database-title {
        text-align: center;
        padding: 1rem;
        background: linear-gradient(135deg, #434343 0%, #000000 100%);
        color: #E0E0E0;
        border-radius: 10px;
        margin-bottom: 1rem;
    }
    
    .stDataFrame {
        background-color: #2D2D2D;
    }
    
    .stDataFrame td, .stDataFrame th {
        color: #E0E0E0 !important;
        background-color: #3D3D3D !important;
    }
    
    .stDataFrame [data-testid="stDataFrameResizeHandle"] {
        background-color: #4D4D4D;
    }
</style>
""", unsafe_allow_html=True)


# 1. ë°ì´í„° ì „ì²˜ë¦¬ ìµœì í™”
@st.cache_data(ttl=3600)
def preprocess_patterns(data):
    """íŒ¨í„´ ë°ì´í„° ì „ì²˜ë¦¬ ë° ìºì‹± - ìµœì í™” ë²„ì „"""
    processed_patterns = []
    
    # ê¸¸ì´ë³„ë¡œ íŒ¨í„´ ë¶„ë¥˜
    short_patterns = []
    medium_patterns = []
    long_patterns = []
    
    for record in data:
        pattern_text = record.get('text', '').lower()
        pattern_text_cleaned = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', pattern_text)
        pattern_words = set(pattern_text_cleaned.split())
        
        processed = {
            'original': record,
            'cleaned_text': pattern_text_cleaned,
            'words': pattern_words,
            'chars': set(pattern_text_cleaned),
            'word_count': len(pattern_words),
            'length': len(pattern_text_cleaned)
        }
        
        # ê¸¸ì´ì— ë”°ë¼ ë¶„ë¥˜
        if processed['length'] <= 10:
            short_patterns.append(processed)
        elif processed['length'] <= 30:
            medium_patterns.append(processed)
        else:
            long_patterns.append(processed)
    
    return {
        'short': short_patterns,
        'medium': medium_patterns,
        'long': long_patterns
    }


# 2. íŒ¨í„´ ë§¤ì¹­ ìµœì í™”
def check_pattern(input_data, pattern_data, threshold=0.7):
    """ë‹¨ì¼ íŒ¨í„´ ë§¤ì¹­ ê²€ì‚¬ - ìµœì í™” ë²„ì „"""
    input_text_cleaned, input_words, input_chars = input_data
    
    # ë¹ ë¥¸ ë¬¸ì ê¸°ë°˜ í•„í„°ë§
    char_intersection = len(input_chars & pattern_data['chars'])
    if char_intersection < min(3, len(pattern_data['chars']) * 0.3):
        return None
    
    # ë‹¨ì–´ ê¸°ë°˜ í•„í„°ë§
    common_words = input_words & pattern_data['words']
    word_match_ratio = len(common_words) / pattern_data['word_count'] if pattern_data['word_count'] > 0 else 0
    
    # ì§§ì€ íŒ¨í„´ì€ í¬í•¨ ì—¬ë¶€ë§Œ ë¹ ë¥´ê²Œ ì²´í¬
    if pattern_data['length'] <= 10:
        if pattern_data['cleaned_text'] in input_text_cleaned:
            similarity = 1.0
        elif word_match_ratio < threshold * 0.5:
            return None
        else:
            similarity = word_match_ratio
    else:
        # ê¸´ íŒ¨í„´ì€ ë‹¨ì–´ ë§¤ì¹­ ë¹„ìœ¨ë¡œ 1ì°¨ í•„í„°ë§
        if word_match_ratio < threshold * 0.5:
            return None
        similarity = difflib.SequenceMatcher(None, input_text_cleaned, pattern_data['cleaned_text']).ratio()
    
    if similarity >= threshold:
        record = pattern_data['original']
        try:
            danger_level = int(record.get('dangerlevel', 0))
        except (ValueError, TypeError):
            danger_level = 0
            
        return {
            'pattern': record['text'],
            'analysis': record['output'],
            'danger_level': danger_level,
            'url': record.get('url', ''),
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'match_score': similarity
        }
    
    return None



@st.cache_data(ttl=300)
def load_sheet_data():
    """Google Sheets ë°ì´í„° ë¡œë“œ"""
    try:
        credentials = {
            "type": "service_account",
            "project_id": st.secrets["gcp_service_account"]["project_id"],
            "private_key_id": st.secrets["gcp_service_account"]["private_key_id"],
            "private_key": st.secrets["gcp_service_account"]["private_key"],
            "client_email": st.secrets["gcp_service_account"]["client_email"],
            "client_id": st.secrets["gcp_service_account"]["client_id"],
            "auth_uri": "https://accounts.google.com/o/oauth2/auth",
            "token_uri": "https://oauth2.googleapis.com/token",
            "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
            "client_x509_cert_url": st.secrets["gcp_service_account"]["client_x509_cert_url"],
            "universe_domain": "googleapis.com"
        }
        
        SCOPES = [
            'https://www.googleapis.com/auth/spreadsheets',
            'https://www.googleapis.com/auth/drive'
        ]
        
        creds = service_account.Credentials.from_service_account_info(
            credentials, scopes=SCOPES)
        client = gspread.authorize(creds)
        
        sheet = client.open_by_url('https://docs.google.com/spreadsheets/d/1wPchxwAssBf706VuvxhGp4ESt3vj-N9RLcMaUF075ug/edit?gid=137455637#gid=137455637')
        worksheet = sheet.get_worksheet(0)
        return worksheet.get_all_records()
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

@st.cache_resource
def get_sheet_instance():
    """ì‹œíŠ¸ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    try:
        credentials = {
            "type": "service_account",
            "project_id": st.secrets["gcp_service_account"]["project_id"],
            "private_key_id": st.secrets["gcp_service_account"]["private_key_id"],
            "private_key": st.secrets["gcp_service_account"]["private_key"],
            "client_email": st.secrets["gcp_service_account"]["client_email"],
            "client_id": st.secrets["gcp_service_account"]["client_id"],
            "auth_uri": "https://accounts.google.com/o/oauth2/auth",
            "token_uri": "https://oauth2.googleapis.com/token",
            "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
            "client_x509_cert_url": st.secrets["gcp_service_account"]["client_x509_cert_url"],
            "universe_domain": "googleapis.com"
        }
        
        SCOPES = [
            'https://www.googleapis.com/auth/spreadsheets',
            'https://www.googleapis.com/auth/drive'
        ]
        
        creds = service_account.Credentials.from_service_account_info(
            credentials, scopes=SCOPES)
        client = gspread.authorize(creds)
        
        sheet = client.open_by_url('https://docs.google.com/spreadsheets/d/1wPchxwAssBf706VuvxhGp4ESt3vj-N9RLcMaUF075ug/edit?gid=137455637#gid=137455637')
        return sheet.get_worksheet(0)
    except Exception as e:
        st.error(f"ì‹œíŠ¸ ì—°ê²° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None


# ìµœìƒìœ„ ë ˆë²¨ì— get_color_style í•¨ìˆ˜ ì •ì˜
def get_color_style(score):
    """ìœ„í—˜ë„ ì ìˆ˜ì— ë”°ë¥¸ ìƒ‰ìƒ ìŠ¤íƒ€ì¼ ë°˜í™˜"""
    if score >= 70:
        return "color: #FF5252; font-weight: bold;"  # ë¹¨ê°„ìƒ‰
    elif score >= 30:
        return "color: #FFD700; font-weight: bold;"  # ë…¸ë€ìƒ‰
    else:
        return "color: #00E676; font-weight: bold;"  # ì´ˆë¡ìƒ‰


def calculate_danger_score(matches):
    """ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°"""
    total_score = 0
    for match in matches:
        total_score += match.get('danger_level', 0)
    return total_score

def get_danger_level_class(score):
    """ìœ„í—˜ë„ ì ìˆ˜ì— ë”°ë¥¸ CSS í´ë˜ìŠ¤ ë°˜í™˜"""
    if score < 30:
        return "danger-level-low"
    elif score < 70:
        return "danger-level-medium"
    else:
        return "danger-level-high"

def get_youtube_thumbnail(url):
    """ìœ íŠœë¸Œ URLì—ì„œ ì¸ë„¤ì¼ URL ì¶”ì¶œ"""
    if not url:
        return None
    video_id = re.search(r"(?:v=|\/)([0-9A-Za-z_-]{11}).*", url)
    if video_id and 'youtube.com' in url:
        return f"https://img.youtube.com/vi/{video_id.group(1)}/hqdefault.jpg"
    return None

# 3. ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
def find_matching_patterns(input_text, data, threshold=0.7):
    """ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™” ë²„ì „ - ìœ ì‚¬ íŒ¨í„´ ê·¸ë£¹í™”"""
    input_text = input_text.strip()
    if not input_text or input_text.isspace():
        return []
    
    # ì…ë ¥ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
    input_text_cleaned = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', input_text.lower())
    input_words = set(w for w in input_text_cleaned.split() if w.strip())
    input_chars = set(input_text_cleaned)
    
    if len(input_words) < 2:
        return []
        
    patterns = preprocess_patterns(data)
    input_data = (input_text_cleaned, input_words, input_chars)
    
    from concurrent.futures import ThreadPoolExecutor, as_completed
    from functools import partial
    
    found_patterns = []
    pattern_groups = {}  # íŒ¨í„´ ê·¸ë£¹ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    
    def get_pattern_key(text):
        """íŒ¨í„´ì˜ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ì •ë ¬ëœ íŠœí”Œë¡œ ë°˜í™˜"""
        cleaned = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', text.lower())
        words = sorted(set(w for w in cleaned.split() if len(w) >= 2))
        return tuple(words)
    
    def merge_patterns(existing, new_pattern):
        """ë‘ íŒ¨í„´ì„ ë³‘í•©"""
        # ìœ„í—˜ë„ëŠ” ìµœëŒ€ê°’ ì‚¬ìš©
        existing['danger_level'] = max(existing['danger_level'], new_pattern['danger_level'])
        # ë§¤ì¹˜ ì ìˆ˜ëŠ” ìµœëŒ€ê°’ ì‚¬ìš©
        existing['match_score'] = max(existing['match_score'], new_pattern['match_score'])
        # í‚¤ì›Œë“œ ë³‘í•©
        existing_keywords = set(existing.get('matched_keywords', []))
        new_keywords = set(new_pattern.get('matched_keywords', []))
        existing['matched_keywords'] = sorted(existing_keywords | new_keywords)
        # URLì´ ìˆëŠ” ê²½ìš° ì¶”ê°€
        if new_pattern.get('url') and not existing.get('url'):
            existing['url'] = new_pattern['url']
        # ë¶„ì„ ë‚´ìš©ì´ ë‹¤ë¥¸ ê²½ìš° ì¶”ê°€
        if new_pattern['analysis'] != existing['analysis']:
            existing['analysis'] = f"{existing['analysis']}\nì¶”ê°€ ë¶„ì„: {new_pattern['analysis']}"
        return existing
    
    def process_pattern_batch(patterns_batch):
        batch_results = []
        check_func = partial(check_pattern, input_data, threshold=threshold)
        for pattern in patterns_batch:
            if not pattern['cleaned_text'].strip():
                continue
            result = check_func(pattern)
            if result:
                result['original_text'] = input_text
                result['matched_keywords'] = extract_keywords(result['pattern'])
                # íŒ¨í„´ í‚¤ ìƒì„±
                pattern_key = get_pattern_key(result['pattern'])
                batch_results.append((pattern_key, result))
        return batch_results
    
    with ThreadPoolExecutor(max_workers=8) as executor:
        futures = []
        
        # ëª¨ë“  ê¸¸ì´ì˜ íŒ¨í„´ì„ ì²˜ë¦¬
        for pattern_type in ['short', 'medium', 'long']:
            patterns_list = patterns[pattern_type]
            chunk_size = max(1, len(patterns_list) // 4)
            for i in range(0, len(patterns_list), chunk_size):
                chunk = patterns_list[i:i + chunk_size]
                futures.append(executor.submit(process_pattern_batch, chunk))
        
        # ê²°ê³¼ ìˆ˜ì§‘ ë° ê·¸ë£¹í™”
        for future in as_completed(futures):
            try:
                results = future.result()
                for pattern_key, result in results:
                    if pattern_key in pattern_groups:
                        pattern_groups[pattern_key] = merge_patterns(pattern_groups[pattern_key], result)
                    else:
                        pattern_groups[pattern_key] = result
            except Exception as e:
                st.error(f"íŒ¨í„´ ë§¤ì¹­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # ê·¸ë£¹í™”ëœ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    found_patterns = list(pattern_groups.values())
    
    # ë§¤ì¹˜ ì ìˆ˜ì™€ ìœ„í—˜ë„ë¡œ ì •ë ¬
    found_patterns.sort(key=lambda x: (x['match_score'], x['danger_level']), reverse=True)
    
    # ìœ íŠœë¸Œ ì¸ë„¤ì¼ ì²˜ë¦¬
    for pattern in found_patterns:
        if pattern.get('url') and 'youtube.com' in pattern['url']:
            thumbnail = get_youtube_thumbnail(pattern['url'])
            if thumbnail:
                pattern['thumbnail'] = thumbnail
    
    return found_patterns

def extract_keywords(text):
    """í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì†Œë¬¸ì ë³€í™˜
    cleaned = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', text.lower())
    # 2ê¸€ì ì´ìƒ ë‹¨ì–´ë§Œ ì¶”ì¶œ
    words = [w for w in cleaned.split() if len(w) >= 2]
    # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    return sorted(set(words))

def display_analysis_results(patterns, total_score):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ - í•˜ì´ë¼ì´íŠ¸ ê¸°ëŠ¥ ì¶”ê°€"""
    danger_level_class = get_danger_level_class(total_score)
    st.markdown(f"""
        <div class="danger-meter">
            <h2>ì „ì²´ ìœ„í—˜ë„ ì ìˆ˜</h2>
            <div class="danger-score {danger_level_class}">{total_score}</div>
        </div>
    """, unsafe_allow_html=True)

    for pattern in patterns:
        danger_level_class = get_danger_level_class(pattern['danger_level'])
        thumbnail_html = ""
        if 'thumbnail' in pattern:
            thumbnail_html = f'<img src="{pattern["thumbnail"]}" style="width:100%; max-width:480px; border-radius:10px; margin-top:10px;">'
        
        # ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ íŒ¨í„´ í•˜ì´ë¼ì´íŠ¸
        highlighted_text = highlight_pattern_in_text(pattern['original_text'], pattern['pattern'])
        
        # ë§¤ì¹˜ ì ìˆ˜ë¥¼ í¼ì„¼íŠ¸ë¡œ í‘œì‹œ
        match_percentage = int(pattern['match_score'] * 100)
        
        st.markdown(f"""
            <div class="analysis-card">
                <h3>ğŸ” ë°œê²¬ëœ íŒ¨í„´:</h3>
                <div class="highlighted-text" style="
                    background-color: #2A2A2A;
                    padding: 15px;
                    border-radius: 8px;
                    margin: 10px 0;
                    line-height: 1.6;
                    font-family: 'Noto Sans KR', sans-serif;">
                    {highlighted_text}
                </div>
                <p>ğŸ“Š ìœ„í—˜ë„: <span class="{danger_level_class}">{pattern['danger_level']}</span></p>
                <p>ğŸ¯ ì¼ì¹˜ìœ¨: {match_percentage}%</p>
                <p>ğŸ“ ë¶„ì„: {pattern['analysis']}</p>
                {f'<p>ğŸ”— <a href="{pattern["url"]}" target="_blank">ì°¸ê³  ìë£Œ</a></p>' if pattern['url'] else ''}
                {thumbnail_html}
            </div>
        """, unsafe_allow_html=True)

def highlight_pattern_in_text(original_text, pattern):
    """í…ìŠ¤íŠ¸ ë‚´ì˜ íŒ¨í„´ì„ í•˜ì´ë¼ì´íŠ¸"""
    # íŒ¨í„´ê³¼ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”
    pattern_cleaned = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', pattern.lower())
    text_cleaned = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', original_text.lower())
    
    # CSS ìŠ¤íƒ€ì¼ì´ ì ìš©ëœ í•˜ì´ë¼ì´íŠ¸ HTML
    highlight_style = """
        background: linear-gradient(104deg, rgba(255, 178, 15, 0.1) 0.9%, rgba(255, 178, 15, 0.3) 2.4%, rgba(255, 178, 15, 0.2) 5.8%, rgba(255, 178, 15, 0.1) 93%, rgba(255, 178, 15, 0.1) 96%);
        border-radius: 4px;
        padding: 0.1em 0.2em;
        box-decoration-break: clone;
        -webkit-box-decoration-break: clone;
        position: relative;
        color: #FFB20F;
        font-weight: 500;
    """
    
    try:
        # íŒ¨í„´ì˜ ê° ë‹¨ì–´ì— ëŒ€í•´ í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬
        pattern_words = pattern_cleaned.split()
        result_text = original_text
        
        for word in pattern_words:
            if len(word) >= 2:  # 2ê¸€ì ì´ìƒì˜ ë‹¨ì–´ë§Œ ì²˜ë¦¬
                # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ë§¤ì¹­í•˜ë˜, ì›ë³¸ í…ìŠ¤íŠ¸ì˜ ëŒ€ì†Œë¬¸ìëŠ” ìœ ì§€
                pattern = re.compile(re.escape(word), re.IGNORECASE)
                result_text = pattern.sub(
                    lambda m: f'<span style="{highlight_style}">{m.group()}</span>',
                    result_text
                )
        
        return result_text
    except Exception as e:
        st.error(f"í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return original_text

# CSS ìŠ¤íƒ€ì¼ ì¶”ê°€
st.markdown("""
<style>
    /* í•˜ì´ë¼ì´íŠ¸ ê´€ë ¨ ìŠ¤íƒ€ì¼ */
    .highlighted-text {
        font-size: 1.1em;
        line-height: 1.6;
    }
    
    /* ê¸°ì¡´ ìŠ¤íƒ€ì¼ì— ì¶”ê°€ */
    .analysis-card {
        position: relative;
        overflow: hidden;
    }
    
    .analysis-card::before {
        content: '';
        position: absolute;
        left: 0;
        top: 0;
        height: 100%;
        width: 4px;
        background: linear-gradient(to bottom, #FFB20F, #FF9800);
    }
</style>
""", unsafe_allow_html=True)

def analyze_file_contents(file_content, data):
    """íŒŒì¼ ë‚´ìš© ë¶„ì„ - ì´ˆê³ ì† ë²„ì „ (í´ë” ë° íƒ€ì… ì²´í¬ ì§€ì›)"""
    import time
    from collections import defaultdict
    import numpy as np
    import zipfile
    import io
    
    if file_content is not None:
        try:
            start_time = time.time()
            
            # ë¡œê·¸ ì»¨í…Œì´ë„ˆ ìƒì„±
            log_container = st.empty()
            def update_log(message):
                log_container.markdown(f"""
                    <div style="background-color: #2D2D2D; padding: 10px; border-radius: 5px; margin: 5px 0;">
                        {message}
                    </div>
                """, unsafe_allow_html=True)

            update_log("ğŸ“‚ íŒŒì¼ ë¡œë”© ë° íŒ¨í„´ ìµœì í™” ì¤‘...")
            
            # íŒŒì¼ ë¡œë“œ ìµœì í™”
            dfs = []
            if hasattr(file_content, 'name'):  # ë‹¨ì¼ íŒŒì¼
                file_type = file_content.name.split('.')[-1].lower()
                if file_type == 'csv':
                    df = pd.read_csv(file_content, dtype=str)
                    df['source_file'] = file_content.name
                    dfs.append(df)
                elif file_type in ['xlsx', 'xls']:
                    df = pd.read_excel(file_content, dtype=str)
                    df['source_file'] = file_content.name
                    dfs.append(df)
                elif file_type == 'zip':  # ZIP íŒŒì¼(í´ë”) ì²˜ë¦¬
                    with zipfile.ZipFile(file_content) as z:
                        for filename in z.namelist():
                            if filename.endswith(('.csv', '.xlsx', '.xls')):
                                with z.open(filename) as f:
                                    if filename.endswith('.csv'):
                                        df = pd.read_csv(io.BytesIO(f.read()), dtype=str)
                                    else:
                                        df = pd.read_excel(io.BytesIO(f.read()), dtype=str)
                                    df['source_file'] = filename
                                    dfs.append(df)

            if not dfs:
                st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì´ê±°ë‚˜ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return None
                
            # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ ë³‘í•©
            df = pd.concat(dfs, ignore_index=True)

            # íŒ¨í„´ ë°ì´í„° ì „ì²˜ë¦¬ ë° ìµœì í™”
            pattern_lookup = defaultdict(list)
            for idx, item in enumerate(data):
                pattern_text = str(item.get('text', '')).lower()
                words = set(re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', pattern_text).split())
                
                # ê° ë‹¨ì–´ë¥¼ í‚¤ë¡œ ì‚¬ìš©í•˜ì—¬ íŒ¨í„´ ì¸ë±ìŠ¤ ì €ì¥
                for word in words:
                    if len(word) >= 2:
                        pattern_lookup[word].append((idx, words))

            update_log("ğŸš€ ì´ˆê³ ì† ë¶„ì„ ì‹œì‘...")

            # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì²˜ë¦¬
            text_columns = df.select_dtypes(include=['object']).columns
            total_patterns_found = 0
            all_results = []
            
            progress_bar = st.progress(0)
            progress_text = st.empty()
            
            def analyze_text_batch(texts, batch_idx, total_batches):
                """í…ìŠ¤íŠ¸ ë°°ì¹˜ ê³ ì† ë¶„ì„"""
                batch_results = []
                potential_matches = defaultdict(set)
                
                # 1ë‹¨ê³„: ë¹ ë¥¸ í‚¤ì›Œë“œ ë§¤ì¹­
                for text_idx, text in enumerate(texts):
                    # ìˆ«ìí˜• ë°ì´í„° ì²˜ë¦¬
                    if isinstance(text, (int, float)):
                        text = str(text)
                    # None ê°’ ì²˜ë¦¬    
                    if not isinstance(text, str):
                        continue
                        
                    text_lower = text.lower()
                    words = set(re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', text_lower).split())
                    
                    # ê° ë‹¨ì–´ì— ëŒ€í•´ ê°€ëŠ¥í•œ íŒ¨í„´ ì°¾ê¸°
                    for word in words:
                        if len(word) >= 2 and word in pattern_lookup:
                            for pattern_idx, pattern_words in pattern_lookup[word]:
                                potential_matches[text_idx].add(pattern_idx)
                
                # 2ë‹¨ê³„: ì •í™•í•œ ë§¤ì¹­ ê²€ì‚¬
                for text_idx, pattern_indices in potential_matches.items():
                    text = texts[text_idx]
                    if isinstance(text, (int, float)):
                        text = str(text)
                    text_lower = text.lower()
                    text_words = set(re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', text_lower).split())
                    
                    for pattern_idx in pattern_indices:
                        pattern_item = data[pattern_idx]
                        pattern_text = str(pattern_item['text']).lower()
                        pattern_words = set(re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', pattern_text).split())
                        
                        # ì›Œë“œ ë§¤ì¹­ ìŠ¤ì½”ì–´ ê³„ì‚°
                        common_words = text_words & pattern_words
                        if common_words:
                            match_score = len(common_words) / len(pattern_words)
                            if match_score >= 0.7:  # ì„ê³„ê°’
                                try:
                                    danger_level = int(pattern_item.get('dangerlevel', 0))
                                except (ValueError, TypeError):
                                    danger_level = 0
                                    
                                batch_results.append({
                                    'text': text,
                                    'pattern': pattern_item['text'],
                                    'analysis': pattern_item['output'],
                                    'danger_level': danger_level,
                                    'url': pattern_item.get('url', ''),
                                    'match_score': match_score,
                                    'source_file': df.iloc[text_idx].get('source_file', 'Unknown')
                                })
                
                return batch_results

            # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°°ì¹˜ ì²˜ë¦¬
            total_rows = df[text_columns].notna().sum().sum()
            processed_rows = 0
            batch_size = 5000  # ëŒ€ìš©ëŸ‰ ë°°ì¹˜
            
            for col_idx, col in enumerate(text_columns):
                if col == 'source_file':  # source_file ì»¬ëŸ¼ ì œì™¸
                    continue
                    
                texts = df[col].dropna().tolist()
                total_batches = (len(texts) + batch_size - 1) // batch_size
                
                for batch_idx in range(total_batches):
                    start_idx = batch_idx * batch_size
                    end_idx = min((batch_idx + 1) * batch_size, len(texts))
                    batch_texts = texts[start_idx:end_idx]
                    
                    # ë°°ì¹˜ ë¶„ì„
                    results = analyze_text_batch(batch_texts, batch_idx, total_batches)
                    if results:
                        # ì»¬ëŸ¼ ì •ë³´ ì¶”ê°€
                        for r in results:
                            r['column'] = col
                        all_results.extend(results)
                        total_patterns_found += len(results)
                    
                    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                    processed_rows += len(batch_texts)
                    progress = min(processed_rows / total_rows, 1.0)
                    progress_bar.progress(progress)
                    
                    if batch_idx % 2 == 0:  # ë¡œê·¸ ì—…ë°ì´íŠ¸ ë¹ˆë„ ì¡°ì ˆ
                        elapsed_time = time.time() - start_time
                        speed = processed_rows / elapsed_time if elapsed_time > 0 else 0
                        update_log(f"""
                            ğŸ“Š ë¶„ì„ ì§„í–‰ ì¤‘:
                            - ì²˜ë¦¬ ì†ë„: {speed:.0f} í–‰/ì´ˆ
                            - ì²˜ë¦¬ëœ í–‰: {processed_rows:,}/{total_rows:,}
                            - ë°œê²¬ëœ íŒ¨í„´: {total_patterns_found:,}ê°œ
                        """)
            
            # ìµœì¢… ê²°ê³¼ ì •ë¦¬
            progress_bar.empty()
            progress_text.empty()
            
            if all_results:
                # ìµœì¢… ì •ë ¬ ë° ì¤‘ë³µ ì œê±°
                seen = set()
                unique_results = []
                for r in sorted(all_results, key=lambda x: (-x['match_score'], -x['danger_level'])):
                    key = (r['text'], r['pattern'])
                    if key not in seen:
                        seen.add(key)
                        unique_results.append(r)
                
                total_time = time.time() - start_time
                update_log(f"""
                    âœ… ë¶„ì„ ì™„ë£Œ:
                    - ì²˜ë¦¬ ì‹œê°„: {total_time:.1f}ì´ˆ
                    - ì²˜ë¦¬ ì†ë„: {total_rows/total_time:.0f} í–‰/ì´ˆ
                    - ì´ ì²˜ë¦¬ëœ í–‰: {processed_rows:,}ê°œ
                    - ë°œê²¬ëœ íŒ¨í„´: {total_patterns_found:,}ê°œ
                """)
                
                return {
                    'total_patterns': len(unique_results),
                    'results': unique_results[:1000]  # ìƒìœ„ 1000ê°œ ê²°ê³¼ë§Œ ë°˜í™˜
                }
            else:
                update_log("âš ï¸ ë°œê²¬ëœ íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
        except Exception as e:
            st.error(f"íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            import traceback
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return None
    return None

import streamlit as st
import html

def display_file_analysis_results(analysis_results):
    """íŒŒì¼ ë¶„ì„ ê²°ê³¼ í‘œì‹œ - ê°œì„ ëœ ë²„ì „"""
    if not analysis_results or not analysis_results['results']:
        st.warning("ğŸ” ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í†µê³„ ê³„ì‚°
    total_score = sum(result['danger_level'] for result in analysis_results['results'])
    avg_score = total_score / len(analysis_results['results']) if analysis_results['results'] else 0
    high_risk_count = sum(1 for r in analysis_results['results'] if r['danger_level'] >= 70)

    # ê²°ê³¼ ì •ë ¬ ë° ê·¸ë£¹í™”
    sorted_results = sorted(
        analysis_results['results'],
        key=lambda x: (x['danger_level'], x['match_score']),
        reverse=True
    )

    # ìœ„í—˜ë„ë³„ ê²°ê³¼ í‘œì‹œ
    for severity in ['high', 'medium', 'low']:
        if severity == 'high':
            results = [r for r in sorted_results if r['danger_level'] >= 70]
            title = "ğŸš¨ ê³ ìœ„í—˜ í•­ëª©"
            border_color = "#FF5252"
        elif severity == 'medium':
            results = [r for r in sorted_results if 30 <= r['danger_level'] < 70]
            title = "âš ï¸ ì£¼ì˜ í•­ëª©"
            border_color = "#FFD700"
        else:
            results = [r for r in sorted_results if r['danger_level'] < 30]
            title = "âœ… ì•ˆì „ í•­ëª©"
            border_color = "#00E676"

        if results:
            st.markdown(f"<h3 style='color:{border_color}; border-left: 6px solid {border_color}; padding-left: 10px;'>{title} ({len(results)}ê°œ)</h3>", unsafe_allow_html=True)

            for result in results:
                match_percentage = int(result['match_score'] * 100)

                with st.container():
                    # ìœ„í—˜ë„, ì¼ì¹˜ìœ¨, ì»¬ëŸ¼ ì •ë³´ í‘œì‹œ
                    cols = st.columns([2, 1, 1])
                    with cols[0]:
                        if result['danger_level'] >= 70:
                            danger_level_text = "ìœ„í—˜"
                            danger_level_color = "#FF5252"
                        elif result['danger_level'] >= 30:
                            danger_level_text = "ì£¼ì˜"
                            danger_level_color = "#FFD700"
                        else:
                            danger_level_text = "ì•ˆì „"
                            danger_level_color = "#00E676"
                        st.markdown(f"<p style='color:#FFFFFF;'><strong>ìœ„í—˜ë„:</strong> <span style='color:{danger_level_color}; font-weight:bold;'>{danger_level_text}</span></p>", unsafe_allow_html=True)
                    with cols[1]:
                        st.markdown(f"<p style='color:#FFFFFF;'><strong>ì¼ì¹˜ìœ¨:</strong> {match_percentage}%</p>", unsafe_allow_html=True)
                    with cols[2]:
                        st.markdown(f"<p style='color:#FFFFFF;'><strong>ì»¬ëŸ¼:</strong> {html.escape(result['column'])}</p>", unsafe_allow_html=True)

                    # ì›ë³¸ í…ìŠ¤íŠ¸ ì„¹ì…˜
                    st.markdown("<div style='font-weight:bold; margin-top: 10px; color: #FFFFFF;'>ì›ë³¸ í…ìŠ¤íŠ¸:</div>", unsafe_allow_html=True)
                    st.markdown(f"<div style='white-space: pre-wrap; font-family: \"Noto Sans KR\", sans-serif; background-color: #333333; padding: 10px; border-radius: 5px; color: #FFFFFF;'>{html.escape(result['text'])}</div>", unsafe_allow_html=True)

                    # ë§¤ì¹­ëœ íŒ¨í„´ ì„¹ì…˜
                    st.markdown("<div style='font-weight:bold; margin-top: 10px; color: #FFFFFF;'>ë§¤ì¹­ëœ íŒ¨í„´:</div>", unsafe_allow_html=True)
                    st.markdown(f"<div style='background-color: #444444; padding: 8px; border-radius: 5px; color: #FFFFFF;'>{html.escape(result['pattern'])}</div>", unsafe_allow_html=True)

                    # ë¶„ì„ ì„¹ì…˜
                    st.markdown("<div style='font-weight:bold; margin-top: 10px; color: #FFFFFF;'>ë¶„ì„:</div>", unsafe_allow_html=True)
                    st.markdown(f"<div style='background-color: rgba{tuple(int(border_color[i:i+2], 16) for i in (1, 3, 5))}, 0.1); padding: 10px; border-radius: 5px; color: #FFFFFF;'>{html.escape(result['analysis'])}</div>", unsafe_allow_html=True)

                    # ì¸ë„¤ì¼ ë° ì°¸ê³  ìë£Œ ë§í¬
                    with st.container():
                        # ì¸ë„¤ì¼ ê°€ì ¸ì˜¤ê¸°
                        thumbnail_url = get_thumbnail_url(result.get("url"))
                        if thumbnail_url:
                            try:
                                response = requests.get(thumbnail_url)
                                image = Image.open(BytesIO(response.content))
                                st.image(image, width=200, use_column_width=False)
                            except:
                                pass

                        # ì°¸ê³  ìë£Œ ë§í¬
                        if result.get("url"):
                            st.markdown(f"<p><strong>ğŸ”— <a href='{html.escape(result['url'])}' target='_blank' style='color:{border_color};'>ì°¸ê³  ìë£Œ</a></strong></p>", unsafe_allow_html=True)

                # êµ¬ë¶„ì„ 
                st.markdown("<hr style='border: none; height: 1px; background-color: #555555;'>", unsafe_allow_html=True)

    # ë¶„ì„ ì™„ë£Œ ë©”ì‹œì§€
    if sorted_results:
        st.success(f"âœ¨ ì´ {analysis_results['total_patterns']}ê°œì˜ íŒ¨í„´ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        st.info("ğŸ‘€ ë°œê²¬ëœ íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤.")

def get_thumbnail_url(url):
    """URLì—ì„œ ì¸ë„¤ì¼ URL ì¶”ì¶œ"""
    if not url:
        return None
    
    # ìœ íŠœë¸Œ URL ì²˜ë¦¬
    video_id = re.search(r"(?:v=|\/)([0-9A-Za-z_-]{11}).*", url)
    if video_id and 'youtube.com' in url:
        return f"https://img.youtube.com/vi/{video_id.group(1)}/hqdefault.jpg"
    
    # ê¸°íƒ€ URL ì²˜ë¦¬
    try:
        response = requests.get(url)
        if 'image/' in response.headers.get('content-type', ''):
            return url
    except:
        pass
    
    return None


# ì¶”ê°€ CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    /* í•˜ì´ë¼ì´íŠ¸ ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼ */
    .highlight-container {
        background-color: #2D2D2D;
        padding: 15px;
        border-radius: 10px;
        margin: 10px 0;
    }
    
    /* íŒŒì¼ ë¶„ì„ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .file-analysis-card {
        background-color: #2D2D2D;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
        border-left: 4px solid transparent;
    }
    
    /* í…ìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼ */
    .text-container {
        background-color: #3D3D3D;
        padding: 15px;
        border-radius: 8px;
        margin: 10px 0;
        line-height: 1.6;
        font-family: 'Noto Sans KR', sans-serif;
    }
</style>
""", unsafe_allow_html=True)



def main():
    st.markdown('<h1 class="main-title">âš ï¸ìŠ¤íŠ¸ë§ í…Œì´ë¸” ë¶„ì„âš ï¸</h1>', unsafe_allow_html=True)
    st.markdown("""
    > ğŸ’¡ ì…ë ¥ëœ ë¬¸ì¥ì„ ë¶„ì„í•˜ê³  ì ìˆ˜í™”í•˜ì—¬ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.
    """)

    # ë°ì´í„° ë¡œë“œ
    data = load_sheet_data()
    if data is None:
        st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # íƒ­ ìƒì„±
    tab1, tab2 = st.tabs(["ğŸ” ë¬¸ì¥ ë¶„ì„", "âœï¸ íŒ¨í„´ ë“±ë¡"])

    with tab1:
        analysis_type = st.radio(
            "ë¶„ì„ ìœ í˜• ì„ íƒ:",
            ["í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥", "íŒŒì¼/í´ë” ì—…ë¡œë“œ"],
            horizontal=True
        )
        
        if analysis_type == "í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥":
            # ... (í…ìŠ¤íŠ¸ ë¶„ì„ ì½”ë“œ ìœ ì§€)
            pass
        
        else:  # íŒŒì¼/í´ë” ì—…ë¡œë“œ
            st.markdown("""
                <div style="background-color: #2D2D2D; padding: 10px; border-radius: 5px; margin-bottom: 10px;">
                    <h4>ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ì•ˆë‚´</h4>
                    <p>â€¢ ë‹¨ì¼ íŒŒì¼: CSV, Excel íŒŒì¼ ì§ì ‘ ì—…ë¡œë“œ</p>
                    <p>â€¢ í´ë” ì—…ë¡œë“œ: ì—¬ëŸ¬ íŒŒì¼ì„ ZIPìœ¼ë¡œ ì••ì¶•í•˜ì—¬ ì—…ë¡œë“œ</p>
                    <p>â€¢ ì§€ì› í˜•ì‹: .csv, .xlsx, .xls, .zip</p>
                </div>
            """, unsafe_allow_html=True)
            
            uploaded_file = st.file_uploader(
                "íŒŒì¼ ë˜ëŠ” ZIP í´ë” ì—…ë¡œë“œ", 
                type=['csv', 'xlsx', 'xls', 'zip'],
                help="ì—¬ëŸ¬ íŒŒì¼ì„ ë¶„ì„í•˜ë ¤ë©´ ZIP íŒŒì¼ë¡œ ì••ì¶•í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”."
            )
            
            if uploaded_file is not None:
                if st.button("ğŸ“‚ íŒŒì¼ ë¶„ì„", use_container_width=True):
                    with st.spinner('ğŸ”„ íŒŒì¼ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                        analysis_results = analyze_file_contents(uploaded_file, data)
                        if analysis_results and analysis_results['total_patterns'] > 0:
                            st.success(f"ğŸ¯ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ {analysis_results['total_patterns']}ê°œì˜ íŒ¨í„´ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            display_file_analysis_results(analysis_results)
                        elif analysis_results:
                            st.info("ğŸ‘€ íŒŒì¼ì—ì„œ ìœ„í—˜ íŒ¨í„´ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    with tab2:
        st.markdown("""
        <div style='background-color: #2D2D2D; padding: 1rem; border-radius: 10px; margin-bottom: 1rem;'>
            <h4>ğŸŒŸ ìƒˆë¡œìš´ íŒ¨í„´ ë“±ë¡</h4>
            <p style='color: #E0E0E0;'>ìƒˆë¡œìš´ ìœ„í—˜ íŒ¨í„´ì„ ë“±ë¡í•´ì£¼ì„¸ìš”.</p>
        </div>
        """, unsafe_allow_html=True)
        
        with st.form("pattern_registration_form", clear_on_submit=True):
            pattern_text = st.text_input("ğŸ·ï¸ íŒ¨í„´:", placeholder="ìœ„í—˜ íŒ¨í„´ì„ ì…ë ¥í•˜ì„¸ìš”")
            analysis_text = st.text_area("ğŸ“ ë¶„ì„:", placeholder="ì´ íŒ¨í„´ì˜ ìœ„í—˜ì„±ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”", height=100)
            danger_level = st.slider("âš ï¸ ìœ„í—˜ë„:", 0, 100, 50)
            url = st.text_input("ğŸ”— ì°¸ê³  URL:", placeholder="ê´€ë ¨ ì°¸ê³  ìë£Œ URL")
            
            col1, col2, col3 = st.columns([1,1,1])
            with col2:
                submit_button = st.form_submit_button("âœ¨ íŒ¨í„´ ë“±ë¡", use_container_width=True)
                    
        if submit_button:
            if all([pattern_text, analysis_text]):
                try:
                    worksheet = get_sheet_instance()
                    if worksheet:
                        worksheet.append_row([
                            pattern_text,
                            analysis_text,
                            url,
                            danger_level,
                            datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        ])
                        st.success("âœ… íŒ¨í„´ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.balloons()
                        # ìºì‹œ ê°±ì‹ 
                        st.cache_data.clear()
                        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                        st.rerun()
                    else:
                        st.error("ì‹œíŠ¸ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                except Exception as e:
                    st.error(f"ğŸ˜¢ íŒ¨í„´ ë“±ë¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            else:
                st.warning("âš ï¸ íŒ¨í„´ê³¼ ë¶„ì„ ë‚´ìš©ì€ í•„ìˆ˜ì…ë‹ˆë‹¤!")
        
        # ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” í‘œì‹œ
        st.markdown("""
        <div class="database-title">
            ğŸ“Š í˜„ì¬ ë“±ë¡ëœ íŒ¨í„´ ë°ì´í„°ë² ì´ìŠ¤
        </div>
        """, unsafe_allow_html=True)
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° í‘œì‹œ
        if data:
            df = pd.DataFrame(data)
            
            # ì»¬ëŸ¼ëª… ë³€ê²½
            column_mapping = {
                'text': 'íŒ¨í„´',
                'output': 'ë¶„ì„',
                'url': 'ì°¸ê³  URL',
                'dangerlevel': 'ìœ„í—˜ë„',
                'timestamp': 'ë“±ë¡ì¼ì‹œ'
            }
            
            # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì´ë¦„ ë³€ê²½
            for old_col, new_col in column_mapping.items():
                if old_col in df.columns:
                    df = df.rename(columns={old_col: new_col})
            
            # ê²€ìƒ‰/í•„í„°ë§ ê¸°ëŠ¥
            search_term = st.text_input("ğŸ” íŒ¨í„´ ê²€ìƒ‰:", placeholder="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
            if search_term:
                pattern_mask = df['íŒ¨í„´'].astype(str).str.contains(search_term, case=False, na=False)
                analysis_mask = df['ë¶„ì„'].astype(str).str.contains(search_term, case=False, na=False)
                df = df[pattern_mask | analysis_mask]
            
            # ìœ„í—˜ë„ í•„í„°ë§
            if 'ìœ„í—˜ë„' in df.columns:
                col1, col2 = st.columns(2)
                with col1:
                    min_danger = st.number_input("ìµœì†Œ ìœ„í—˜ë„:", min_value=0, max_value=100, value=0)
                with col2:
                    max_danger = st.number_input("ìµœëŒ€ ìœ„í—˜ë„:", min_value=0, max_value=100, value=100)
                
                df['ìœ„í—˜ë„'] = pd.to_numeric(df['ìœ„í—˜ë„'], errors='coerce')
                df = df[(df['ìœ„í—˜ë„'] >= min_danger) & (df['ìœ„í—˜ë„'] <= max_danger)]
            
            # í…Œì´ë¸” í‘œì‹œ
            st.dataframe(
                df,
                use_container_width=True,
                hide_index=True,
                height=400
            )
            
            # í†µê³„ ì •ë³´ í‘œì‹œ
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì´ íŒ¨í„´ ìˆ˜", len(df))
            if 'ìœ„í—˜ë„' in df.columns:
                with col2:
                    st.metric("í‰ê·  ìœ„í—˜ë„", f"{df['ìœ„í—˜ë„'].mean():.1f}")
                with col3:
                    st.metric("ê³ ìœ„í—˜ íŒ¨í„´ ìˆ˜", len(df[df['ìœ„í—˜ë„'] >= 70]))
        else:
            st.info("ë“±ë¡ëœ íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()