import streamlit as st
import gspread
from google.oauth2 import service_account
import re
import difflib
import json
from datetime import datetime
import os
import pandas as pd
import html
import requests
from PIL import Image
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor
import gc

# ì „ì—­ ìºì‹œ ì„¤ì •
spelling_cache = {}

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="í…ìŠ¤íŠ¸ í•„í„°",
    page_icon="âš ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': "ë¬¸ì¥ì˜ ìœ„í—˜ë„ë¥¼ ë¶„ì„í•´ë“œë¦½ë‹ˆë‹¤."
    }
)

# CSS ìŠ¤íƒ€ì¼ë§ (ê¸°ì¡´ CSS ì½”ë“œëŠ” ìœ ì§€)
st.markdown("""
<style>
    /* ê¸°ì¡´ CSS ìŠ¤íƒ€ì¼ ... */
</style>
""", unsafe_allow_html=True)

def check_spelling(text):
    """ìì²´ êµ¬í˜„ ë§ì¶¤ë²• ê²€ì‚¬ í•¨ìˆ˜ - ìºì‹œ ì ìš©"""
    try:
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = hash(text)
        if cache_key in spelling_cache:
            return spelling_cache[cache_key]
            
        # ìì£¼ ë°œìƒí•˜ëŠ” ë§ì¶¤ë²• ì˜¤ë¥˜ ì‚¬ì „
        corrections = {
            # ê¸°ì¡´ ë§ì¶¤ë²• ê·œì¹™ ìœ ì§€
        }
        
        # ì´ˆê¸° í…ìŠ¤íŠ¸
        corrected_text = text
        error_count = 0
        corrections_made = []
        
        # ê° êµì • ê·œì¹™ ì ìš©
        for wrong, right in corrections.items():
            if wrong in corrected_text:
                count = corrected_text.count(wrong)
                if count > 0:
                    error_count += count
                    corrections_made.append((wrong, right, count))
                corrected_text = corrected_text.replace(wrong, right)
        
        result = {
            'checked': corrected_text,
            'errors': error_count,
            'corrections': corrections_made,
            'original': text
        }
        
        # ê²°ê³¼ ìºì‹±
        spelling_cache[cache_key] = result
        return result
        
    except Exception as e:
        st.error(f"ë§ì¶¤ë²• ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def analyze_text_batch(texts, batch_idx, total_batches, source_file, column, data, spell_check_enabled=True):
    """í…ìŠ¤íŠ¸ ë°°ì¹˜ ê³ ì† ë¶„ì„ - ìµœì í™” ë²„ì „"""
    batch_results = []
    
    # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ë¥¼ í•œ ë²ˆì— ìˆ˜í–‰
    processed_texts = [str(text) if text is not None else "" for text in texts]
    
    # ë§ì¶¤ë²• ê²€ì‚¬ë¥¼ ë°°ì¹˜ë¡œ ì²˜ë¦¬ (í™œì„±í™”ëœ ê²½ìš°)
    spelling_results = {}
    if spell_check_enabled:
        for idx, text in enumerate(processed_texts):
            if text.strip():
                # ìºì‹œ í‚¤ ìƒì„±
                cache_key = hash(text)
                if cache_key not in spelling_cache:
                    spelling_cache[cache_key] = check_spelling(text)
                spelling_results[idx] = spelling_cache[cache_key]
    
    # íŒ¨í„´ ë§¤ì¹­ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬
    for idx, text in enumerate(processed_texts):
        if not text.strip():
            continue
            
        # íŒ¨í„´ ë§¤ì¹­ ìˆ˜í–‰
        found_patterns = find_matching_patterns(text, data)
        
        # ê²°ê³¼ ì €ì¥
        for pattern in found_patterns:
            result = {
                'text': text,
                'pattern': pattern['pattern'],
                'analysis': pattern['analysis'],
                'danger_level': pattern['danger_level'],
                'url': pattern.get('url', ''),
                'match_score': pattern['match_score'],
                'source_file': source_file,
                'column': column
            }
            
            # ë§ì¶¤ë²• ê²€ì‚¬ ê²°ê³¼ ì¶”ê°€
            if idx in spelling_results and spelling_results[idx]['errors'] > 0:
                result['spelling_check'] = spelling_results[idx]
                
            batch_results.append(result)
    
    return batch_results

def process_batch_and_clear(batch_results):
    """ë°°ì¹˜ ê²°ê³¼ ì²˜ë¦¬ ë° ë©”ëª¨ë¦¬ ì •ë¦¬"""
    if batch_results:
        results = batch_results
        patterns_found = len(batch_results)
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()
        
        return results, patterns_found
    return [], 0

def analyze_file_contents(file_content, data, spell_check_enabled=True, progress_bar=None, progress_text=None):
    """íŒŒì¼ ë‚´ìš© ë¶„ì„ - ìµœì í™” ë²„ì „"""
    import time
    from collections import defaultdict
    import numpy as np
    import zipfile
    import io
    
    if file_content is not None:
        try:
            start_time = time.time()
            
            # ë¡œê·¸ ì»¨í…Œì´ë„ˆ ìƒì„±
            log_container = st.empty()
            def update_log(message, filename=""):
                prefix = f"[{filename}] " if filename else ""
                log_container.markdown(f"""
                    <div style="background-color: #2D2D2D; padding: 10px; border-radius: 5px; margin: 5px 0;">
                        {prefix}{message}
                    </div>
                """, unsafe_allow_html=True)

            # íŒŒì¼ ë¡œë“œ ìµœì í™”
            dfs = []
            filename = getattr(file_content, 'name', 'ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼')
            update_log("ğŸ“‚ íŒŒì¼ ë¡œë”© ë° íŒ¨í„´ ìµœì í™” ì¤‘...", filename)
            
            # íŒŒì¼ ì²˜ë¦¬ ë¡œì§ - ë©”ëª¨ë¦¬ ìµœì í™”
            if hasattr(file_content, 'name'):
                file_type = file_content.name.split('.')[-1].lower()
                chunk_size = 10000  # ì²­í¬ ë‹¨ìœ„ë¡œ íŒŒì¼ ì½ê¸°
                
                if file_type == 'csv':
                    for chunk in pd.read_csv(file_content, dtype=str, chunksize=chunk_size):
                        chunk['source_file'] = file_content.name
                        dfs.append(chunk)
                elif file_type in ['xlsx', 'xls']:
                    df = pd.read_excel(file_content, dtype=str)
                    df['source_file'] = file_content.name
                    dfs.append(df)
                elif file_type == 'zip':
                    with zipfile.ZipFile(file_content) as z:
                        for zip_filename in z.namelist():
                            if zip_filename.endswith(('.csv', '.xlsx', '.xls')):
                                with z.open(zip_filename) as f:
                                    if zip_filename.endswith('.csv'):
                                        for chunk in pd.read_csv(io.BytesIO(f.read()), dtype=str, chunksize=chunk_size):
                                            chunk['source_file'] = zip_filename
                                            dfs.append(chunk)
                                    else:
                                        df = pd.read_excel(io.BytesIO(f.read()), dtype=str)
                                        df['source_file'] = zip_filename
                                        dfs.append(df)

            if not dfs:
                update_log(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì´ê±°ë‚˜ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.", filename)
                return None
                
            update_log(f"ğŸ” {len(dfs)}ê°œì˜ íŒŒì¼ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.", filename)
            
            # ë°ì´í„°í”„ë ˆì„ ì²˜ë¦¬ ìµœì í™”
            df = pd.concat(dfs, ignore_index=True)
            del dfs  # ë©”ëª¨ë¦¬ í•´ì œ
            gc.collect()
            
            # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ìµœì í™”
            text_columns = [col for col in df.select_dtypes(include=['object']).columns if col != 'source_file']
            
            update_log("ğŸš€ ì´ˆê³ ì† ë¶„ì„ ì‹œì‘...", filename)

            total_patterns_found = 0
            all_results = []
            
            # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
            batch_size = 10000
            max_workers = 4
            total_rows = df[text_columns].notna().sum().sum()
            processed_rows = 0
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = []
                
                for col in text_columns:
                    texts = df[col].dropna().tolist()
                    source_files = df.loc[df[col].notna(), 'source_file'].tolist()
                    total_batches = (len(texts) + batch_size - 1) // batch_size
                    
                    for batch_idx in range(total_batches):
                        start_idx = batch_idx * batch_size
                        end_idx = min((batch_idx + 1) * batch_size, len(texts))
                        batch_texts = texts[start_idx:end_idx]
                        batch_sources = source_files[start_idx:end_idx]
                        
                        future = executor.submit(
                            analyze_text_batch,
                            batch_texts,
                            batch_idx,
                            total_batches,
                            batch_sources[0],
                            col,
                            data,
                            spell_check_enabled
                        )
                        futures.append((future, len(batch_texts)))
                
                # ê²°ê³¼ ìˆ˜ì§‘ ë° ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                for future, batch_length in futures:
                    results = future.result()
                    if results:
                        processed_results, patterns_found = process_batch_and_clear(results)
                        all_results.extend(processed_results)
                        total_patterns_found += patterns_found
                    
                    processed_rows += batch_length
                    if progress_bar is not None:
                        progress = min(processed_rows / total_rows, 1.0)
                        progress_bar.progress(progress)
                        
                    if processed_rows % (batch_size * 2) == 0:
                        elapsed_time = time.time() - start_time
                        speed = processed_rows / elapsed_time if elapsed_time > 0 else 0
                        update_log(f"""
                            ğŸ“Š ë¶„ì„ ì§„í–‰ ì¤‘:
                            - ì²˜ë¦¬ ì†ë„: {speed:.0f} í–‰/ì´ˆ
                            - ì²˜ë¦¬ëœ í–‰: {processed_rows:,}/{total_rows:,}
                            - ë°œê²¬ëœ íŒ¨í„´: {total_patterns_found:,}ê°œ
                        """, filename)
            
            # ìµœì¢… ê²°ê³¼ ì •ë¦¬
            if all_results:
                seen = set()
                unique_results = []
                for r in sorted(all_results, key=lambda x: (-x.get('match_score', 0), -x.get('danger_level', 0))):
                    key = (r['text'], r['pattern'], r['source_file'])
                    if key not in seen:
                        seen.add(key)
                        unique_results.append(r)
                
                total_time = time.time() - start_time
                update_log(f"""
                    âš ï¸ ë¶„ì„ ì™„ë£Œ:
                    - ì²˜ë¦¬ ì‹œê°„: {total_time:.1f}ì´ˆ
                    - ì²˜ë¦¬ ì†ë„: {total_rows/total_time:.0f} í–‰/ì´ˆ
                    - ì´ ì²˜ë¦¬ëœ í–‰: {processed_rows:,}ê°œ
                    - ë°œê²¬ëœ íŒ¨í„´: {total_patterns_found:,}ê°œ
                """, filename)
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                gc.collect()
                
                return {
                    'total_patterns': len(unique_results),
                    'results': unique_results[:1000],
                    'filename': filename
                }
            else:
                update_log(f"âœ… {filename}ì—ì„œ ë°œê²¬ëœ íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
        except Exception as e:
            st.error(f"'{filename}' íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            import traceback
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return None
            
    return None

# Google Sheets ê´€ë ¨ í•¨ìˆ˜ ìµœì í™”
@st.cache_data(ttl=300)
def load_sheet_data():
    """Google Sheets ë°ì´í„° ë¡œë“œ - ìºì‹œ ì ìš©"""
    try:
        credentials = {
            "type": "service_account",
            "project_id": st.secrets["gcp_service_account"]["project_id"],
            "private_key_id": st.secrets["gcp_service_account"]["private_key_id"],
            "private_key": st.secrets["gcp_service_account"]["private_key"],
            "client_email": st.secrets["gcp_service_account"]["client_email"],
            "client_id": st.secrets["gcp_service_account"]["client_id"],
            "auth_uri": "https://accounts.google.com/o/oauth2/auth",
            "token_uri": "https://oauth2.googleapis.com/token",
            "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
            "client_x509_cert_url": st.secrets["gcp_service_account"]["client_x509_cert_url"],
            "universe_domain": "googleapis.com"
        }
        
        SCOPES = [
            'https://www.googleapis.com/auth/spreadsheets',
            'https://www.googleapis.com/auth/drive'
        ]
        
        creds = service_account.Credentials.from_service_account_info(
            credentials, scopes=SCOPES)
        client = gspread.authorize(creds)
        
        sheet = client.open_by_url(st.secrets["sheet_url"])
        worksheet = sheet.get_worksheet(0)
        data = worksheet.get_all_records()
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        for item in data:
            item['text'] = str(item.get('text', ''))
            item['output'] = str(item.get('output', ''))
            item['dangerlevel'] = int(item.get('dangerlevel', 0))
            
        return data
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

@st.cache_resource
def get_sheet_instance():
    """ì‹œíŠ¸ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° - ë¦¬ì†ŒìŠ¤ ìºì‹œ ì ìš©"""
    try:
        credentials = {
            "type": "service_account",
            "project_id": st.secrets["gcp_service_account"]["project_id"],
            "private_key_id": st.secrets["gcp_service_account"]["private_key_id"],
            "private_key": st.secrets["gcp_service_account"]["private_key"],
            "client_email": st.secrets["gcp_service_account"]["client_email"],
            "client_id": st.secrets["gcp_service_account"]["client_id"],
            "auth_uri": "https://accounts.google.com/o/oauth2/auth",
            "token_uri": "https://oauth2.googleapis.com/token",
            "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
            "client_x509_cert_url": st.secrets["gcp_service_account"]["client_x509_cert_url"],
            "universe_domain": "googleapis.com"
        }
        
        SCOPES = [
            'https://www.googleapis.com/auth/spreadsheets',
            'https://www.googleapis.com/auth/drive'
        ]
        
        creds = service_account.Credentials.from_service_account_info(
            credentials, scopes=SCOPES)
        client = gspread.authorize(creds)
        
        sheet = client.open_by_url(st.secrets["sheet_url"])
        return sheet.get_worksheet(0)
    except Exception as e:
        st.error(f"ì‹œíŠ¸ ì—°ê²° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# íŒ¨í„´ ë§¤ì¹­ ìµœì í™” í•¨ìˆ˜
@st.cache_data(ttl=3600)
def preprocess_patterns(data):
    """íŒ¨í„´ ë°ì´í„° ì „ì²˜ë¦¬ ë° ìºì‹± - ìµœì í™” ë²„ì „"""
    if not data:
        st.error("ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return {
            'short': [],
            'medium': [],
            'long': []
        }
    
    try:
        # íŒ¨í„´ ë¶„ë¥˜ë¥¼ ë”•ì…”ë„ˆë¦¬ ì»´í”„ë¦¬í—¨ì…˜ìœ¼ë¡œ ìµœì í™”
        patterns = {
            'short': [],
            'medium': [],
            'long': []
        }
        
        for record in data:
            if not isinstance(record, dict) or 'text' not in record:
                continue
                
            pattern_text = str(record.get('text', '')).lower()
            if not pattern_text.strip():
                continue
                
            try:
                pattern_text_cleaned = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', pattern_text)
                pattern_words = {w for w in pattern_text_cleaned.split() if w.strip()}
                
                processed = {
                    'original': record,
                    'cleaned_text': pattern_text_cleaned,
                    'words': pattern_words,
                    'chars': set(pattern_text_cleaned),
                    'word_count': len(pattern_words),
                    'length': len(pattern_text_cleaned)
                }
                
                # ê¸¸ì´ì— ë”°ë¥¸ ë¶„ë¥˜
                if processed['length'] <= 10:
                    patterns['short'].append(processed)
                elif processed['length'] <= 30:
                    patterns['medium'].append(processed)
                else:
                    patterns['long'].append(processed)
                    
            except Exception as e:
                st.error(f"íŒ¨í„´ '{pattern_text}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                continue
        
        if not any(patterns.values()):
            st.warning("ì²˜ë¦¬ëœ íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        return patterns
        
    except Exception as e:
        st.error(f"ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return {'short': [], 'medium': [], 'long': []}

def find_matching_patterns(input_text, data, threshold=0.7):
    """í…ìŠ¤íŠ¸ íŒ¨í„´ ë§¤ì¹­ - ìµœì í™” ë²„ì „"""
    if not data or not input_text:
        return []
        
    input_text = str(input_text).strip()
    if not input_text or input_text.isspace():
        return []
    
    try:
        # ì „ì²˜ë¦¬ëœ íŒ¨í„´ ê°€ì ¸ì˜¤ê¸°
        patterns = preprocess_patterns(data)
        
        # ì…ë ¥ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        input_cleaned = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', input_text.lower())
        input_words = {w for w in input_cleaned.split() if w.strip()}
        input_chars = set(input_cleaned)
        
        # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
        matches = []
        
        # ê° íŒ¨í„´ ê¸¸ì´ë³„ë¡œ ë§¤ì¹­
        for pattern_type in ['short', 'medium', 'long']:
            for pattern in patterns[pattern_type]:
                try:
                    # ë¹ ë¥¸ í•„í„°ë§
                    if not (input_chars & pattern['chars']):
                        continue
                        
                    # ë‹¨ì–´ ê¸°ë°˜ ë§¤ì¹­
                    common_words = input_words & pattern['words']
                    if not common_words:
                        continue
                        
                    match_ratio = len(common_words) / pattern['word_count']
                    if match_ratio < threshold * 0.7:
                        continue
                    
                    # ìµœì¢… ìœ ì‚¬ë„ ê³„ì‚°
                    similarity = difflib.SequenceMatcher(
                        None,
                        input_cleaned,
                        pattern['cleaned_text']
                    ).ratio()
                    
                    if similarity >= threshold:
                        record = pattern['original']
                        matches.append({
                            'pattern': record['text'],
                            'analysis': record.get('output', ''),
                            'danger_level': int(record.get('dangerlevel', 0)),
                            'url': record.get('url', ''),
                            'match_score': similarity,
                            'original_text': input_text
                        })
                        
                except Exception as e:
                    continue
        
        return sorted(matches, key=lambda x: (-x['match_score'], -x['danger_level']))
        
    except Exception as e:
        st.error(f"íŒ¨í„´ ë§¤ì¹­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []
    
 def main():
    st.markdown('<h1 class="main-title">StringAnalysis</h1>', unsafe_allow_html=True)
    st.markdown("""
    > ğŸ’¡ ì…ë ¥ëœ ë¬¸ì¥ì„ ë¶„ì„í•˜ê³  ì ìˆ˜í™”í•˜ì—¬ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.
    """)

    # ë°ì´í„° ë¡œë“œ ë° ê²€ì¦
    try:
        with st.spinner('ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...'):
            data = load_sheet_data()
            if not data:
                st.error("íŒ¨í„´ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return
                
            if not isinstance(data, list) or not data:
                st.error("íŒ¨í„´ ë°ì´í„° í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return
                
            # ë°ì´í„° êµ¬ì¡° ê²€ì¦
            required_fields = ['text', 'output', 'dangerlevel']
            if not all(isinstance(item, dict) and all(field in item for field in required_fields) for item in data):
                st.error("íŒ¨í„´ ë°ì´í„°ì— í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
                return
            
        # íƒ­ ìƒì„±
        tab1, tab2, tab3 = st.tabs(["ğŸ” ë¬¸ì¥ ë¶„ì„", "âœï¸ íŒ¨í„´ ë“±ë¡", "ğŸ“ ë§ì¶¤ë²• ê²€ì‚¬"])

        with tab1:
            analysis_type = st.radio(
                "ë¶„ì„ ìœ í˜• ì„ íƒ:",
                ["í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥", "íŒŒì¼/í´ë” ì—…ë¡œë“œ"],
                horizontal=True
            )
            
            if analysis_type == "í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥":
                col1, col2 = st.columns([3, 1])
                with col1:
                    input_text = st.text_area(
                        "ë¶„ì„í•  ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”:",
                        placeholder="ë¶„ì„í•˜ê³  ì‹¶ì€ ë¬¸ì¥ì„ ì…ë ¥í•´ì£¼ì„¸ìš”...",
                        height=100
                    )
                with col2:
                    st.write("")
                    st.write("")
                    analyze_button = st.button("ğŸ” ìœ„í—˜ë„ ë¶„ì„", use_container_width=True, key="analyze")
                    spell_check = st.checkbox("ë§ì¶¤ë²• ê²€ì‚¬ í¬í•¨", value=True)
                
                if analyze_button and input_text:
                    with st.spinner('ğŸ”„ ë¬¸ì¥ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                        # ìœ„í—˜ë„ ë¶„ì„
                        found_patterns = find_matching_patterns(input_text, data)
                        if found_patterns:
                            total_score = calculate_danger_score(found_patterns)
                            st.success(f"ğŸ¯ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! {len(found_patterns)}ê°œì˜ íŒ¨í„´ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            display_analysis_results(found_patterns, total_score)
                        else:
                            st.info("ğŸ‘€ íŠ¹ë³„í•œ ìœ„í—˜ íŒ¨í„´ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                        
                        # ë§ì¶¤ë²• ê²€ì‚¬
                        if spell_check:
                            with st.spinner('ğŸ”„ ë§ì¶¤ë²• ê²€ì‚¬ ì¤‘...'):
                                spelling_result = check_spelling(input_text)
                                if spelling_result:
                                    display_spelling_check(spelling_result)
            
            else:  # íŒŒì¼/í´ë” ì—…ë¡œë“œ
                st.markdown("""
                    <div style="background-color: #2D2D2D; padding: 10px; border-radius: 5px; margin-bottom: 10px;">
                        <h4>ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ì•ˆë‚´</h4>
                        <p>â€¢ ë‹¨ì¼/ë‹¤ì¤‘ íŒŒì¼: CSV, Excel íŒŒì¼ ì§ì ‘ ì—…ë¡œë“œ</p>
                        <p>â€¢ í´ë” ì—…ë¡œë“œ: ì—¬ëŸ¬ íŒŒì¼ì„ ZIPìœ¼ë¡œ ì••ì¶•í•˜ì—¬ ì—…ë¡œë“œ</p>
                        <p>â€¢ ì§€ì› í˜•ì‹: .csv, .xlsx, .xls, .zip</p>
                    </div>
                """, unsafe_allow_html=True)
                
                uploaded_files = st.file_uploader(
                    "íŒŒì¼ ë˜ëŠ” ZIP í´ë” ì—…ë¡œë“œ", 
                    type=['csv', 'xlsx', 'xls', 'zip'],
                    accept_multiple_files=True,
                    help="ì—¬ëŸ¬ íŒŒì¼ì„ í•œ ë²ˆì— ì„ íƒí•˜ê±°ë‚˜, ZIP íŒŒì¼ë¡œ ì••ì¶•í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”."
                )
                
                col1, col2 = st.columns(2)
                with col1:
                    spell_check_files = st.checkbox("ë§ì¶¤ë²• ê²€ì‚¬ í¬í•¨", value=True)
                
                if uploaded_files:
                    if st.button("ğŸ“‚ íŒŒì¼ ë¶„ì„", use_container_width=True):
                        all_results = []
                        total_patterns = 0
                        
                        # í”„ë¡œê·¸ë ˆìŠ¤ ë°”ì™€ í…ìŠ¤íŠ¸ ìƒì„±
                        progress_text = st.empty()
                        progress_bar = st.progress(0)
                        
                        try:
                            # ê° íŒŒì¼ ì²˜ë¦¬
                            for idx, file in enumerate(uploaded_files):
                                with st.spinner(f'ğŸ”„ {file.name} ë¶„ì„ ì¤‘...'):
                                    analysis_result = analyze_file_contents(
                                        file, 
                                        data,
                                        spell_check_enabled=spell_check_files,
                                        progress_bar=progress_bar,
                                        progress_text=progress_text
                                    )
                                    
                                    if analysis_result and analysis_result['total_patterns'] > 0:
                                        all_results.extend(analysis_result['results'])
                                        total_patterns += analysis_result['total_patterns']
                            
                            # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                            if total_patterns > 0:
                                st.success(f"ğŸ¯ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ {total_patterns}ê°œì˜ íŒ¨í„´ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                
                                combined_results = {
                                    'total_patterns': total_patterns,
                                    'results': sorted(all_results, 
                                                key=lambda x: (x['danger_level'], x['match_score']), 
                                                reverse=True)[:1000]
                                }
                                display_file_analysis_results(combined_results)
                            else:
                                st.info("ğŸ‘€ íŒŒì¼ì—ì„œ ìœ„í—˜ íŒ¨í„´ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                                
                        except Exception as e:
                            st.error(f"íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                        finally:
                            # í”„ë¡œê·¸ë ˆìŠ¤ ë°”ì™€ í…ìŠ¤íŠ¸ ì œê±°
                            progress_bar.empty()
                            progress_text.empty()
                            
                            # ë©”ëª¨ë¦¬ ì •ë¦¬
                            gc.collect()

        with tab2:
            st.markdown("""
            <div style='background-color: #2D2D2D; padding: 1rem; border-radius: 10px; margin-bottom: 1rem;'>
                <h4>ğŸŒŸ ìƒˆë¡œìš´ íŒ¨í„´ ë“±ë¡</h4>
                <p style='color: #E0E0E0;'>ìƒˆë¡œìš´ ìœ„í—˜ íŒ¨í„´ì„ ë“±ë¡í•´ì£¼ì„¸ìš”.</p>
            </div>
            """, unsafe_allow_html=True)
            
            with st.form("pattern_registration_form", clear_on_submit=True):
                pattern_text = st.text_input("ğŸ·ï¸ íŒ¨í„´:", placeholder="ìœ„í—˜ íŒ¨í„´ì„ ì…ë ¥í•˜ì„¸ìš”")
                analysis_text = st.text_area("ğŸ“ ë¶„ì„:", placeholder="ì´ íŒ¨í„´ì˜ ìœ„í—˜ì„±ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”", height=100)
                danger_level = st.slider("âš ï¸ ìœ„í—˜ë„:", 0, 100, 50)
                url = st.text_input("ğŸ”— ì°¸ê³  URL:", placeholder="ê´€ë ¨ ì°¸ê³  ìë£Œ URL")
                
                col1, col2, col3 = st.columns([1,1,1])
                with col2:
                    submit_button = st.form_submit_button("âœ¨ íŒ¨í„´ ë“±ë¡", use_container_width=True)
                        
            if submit_button:
                if all([pattern_text, analysis_text]):
                    try:
                        worksheet = get_sheet_instance()
                        if worksheet:
                            worksheet.append_row([
                                pattern_text,
                                analysis_text,
                                url,
                                danger_level,
                                datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            ])
                            st.success("âœ… íŒ¨í„´ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.balloons()
                            st.cache_data.clear()
                            st.rerun()
                        else:
                            st.error("ì‹œíŠ¸ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        st.error(f"ğŸ˜¢ íŒ¨í„´ ë“±ë¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                else:
                    st.warning("âš ï¸ íŒ¨í„´ê³¼ ë¶„ì„ ë‚´ìš©ì€ í•„ìˆ˜ì…ë‹ˆë‹¤!")

        with tab3:
            st.markdown("""
                <div style='background-color: #2D2D2D; padding: 1rem; border-radius: 10px; margin-bottom: 1rem;'>
                    <h4>ğŸ“ ë§ì¶¤ë²• ê²€ì‚¬</h4>
                    <p style='color: #E0E0E0;'>í…ìŠ¤íŠ¸ì˜ ë§ì¶¤ë²•ì„ ê²€ì‚¬í•©ë‹ˆë‹¤.</p>
                </div>
            """, unsafe_allow_html=True)
            
            spell_text = st.text_area(
                "ê²€ì‚¬í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
                placeholder="ë§ì¶¤ë²•ì„ ê²€ì‚¬í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”...",
                height=150
            )
            
            if st.button("âœ¨ ë§ì¶¤ë²• ê²€ì‚¬", use_container_width=True):
                if spell_text:
                    with st.spinner('ğŸ”„ ë§ì¶¤ë²•ì„ ê²€ì‚¬í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                        spelling_result = check_spelling(spell_text)
                        if spelling_result:
                            display_spelling_check(spelling_result)
                else:
                    st.warning("âš ï¸ ê²€ì‚¬í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
                
    except Exception as e:
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return

if __name__ == "__main__":
    main()   