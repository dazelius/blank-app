import streamlit as st
import gspread
from google.oauth2 import service_account
import re
import difflib
import json
from datetime import datetime
import os
import pandas as pd
import streamlit as st
import html
import requests
from PIL import Image
from io import BytesIO

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="í…ìŠ¤íŠ¸ í•„í„°",
    page_icon="âš ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': "ë¬¸ì¥ì˜ ìœ„í—˜ë„ë¥¼ ë¶„ì„í•´ë“œë¦½ë‹ˆë‹¤."
    }
)

# Open Graph ë©”íƒ€ íƒœê·¸ ìˆ˜ì •
st.markdown('''
    <head>
        <title>í…ìŠ¤íŠ¸ í•„í„°</title>
        <meta property="og:title" content="í…ìŠ¤íŠ¸ í•„í„°"/>
        <meta property="og:description" content="í…ìŠ¤íŠ¸ í•„í„°"/>
        <meta property="og:image" content="í…ìŠ¤íŠ¸ í•„í„°"/>
    </head>''', unsafe_allow_html=True)

# CSS ìŠ¤íƒ€ì¼ ì—…ë°ì´íŠ¸
st.markdown("""
<style>
    /* ë‹¤í¬ëª¨ë“œ ê¸°ë³¸ ë°°ê²½ ë° í…ìŠ¤íŠ¸ ìƒ‰ìƒ */
    .stApp {
        background-color: #1E1E1E;
        color: #E0E0E0;
    }
    
    /* ë©”ì¸ íƒ€ì´í‹€ ìŠ¤íƒ€ì¼ */
    .main-title {
        text-align: center;
        padding: 1.5rem;
        background: linear-gradient(135deg, #434343 0%, #000000 100%);
        color: #E0E0E0;
        border-radius: 15px;
        margin-bottom: 2rem;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
    }
    
    /* ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .analysis-card {
        background: #2D2D2D;
        padding: 1.5rem;
        border-radius: 15px;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
        margin-bottom: 1rem;
        color: #E0E0E0;
    }
    
    /* ìœ„í—˜ë„ ë¯¸í„° ìŠ¤íƒ€ì¼ */
    .danger-meter {
        text-align: center;
        padding: 2rem;
        margin: 1rem 0;
        border-radius: 15px;
        background: #2D2D2D;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
    }
    
    /* ì…ë ¥ í•„ë“œ ìŠ¤íƒ€ì¼ */
    .stTextInput>div>div>input {
        background-color: #3D3D3D;
        color: #E0E0E0;
        border-color: #4D4D4D;
    }
    
    .stTextArea>div>div>textarea {
        background-color: #3D3D3D;
        color: #E0E0E0;
        border-color: #4D4D4D;
    }
    
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton>button {
        background: linear-gradient(to right, #434343 0%, #000000 100%);
        color: #E0E0E0;
        border: none;
        padding: 0.5rem 1rem;
        border-radius: 10px;
        font-weight: 600;
        transition: transform 0.2s;
    }
    
    .stButton>button:hover {
        transform: translateY(-2px);
        background: linear-gradient(to right, #4a4a4a 0%, #1a1a1a 100%);
    }
    
    /* íƒ­ ìŠ¤íƒ€ì¼ */
    .stTabs [data-baseweb="tab-list"] {
        background-color: #2D2D2D;
        border-radius: 15px;
    }
    
    .stTabs [data-baseweb="tab"] {
        color: #E0E0E0;
    }
    
    /* ë§í¬ ìŠ¤íƒ€ì¼ */
    a {
        color: #00B4DB;
        text-decoration: none;
    }
    
    a:hover {
        text-decoration: underline;
        color: #00D4FF;
    }
    
    /* ìœ„í—˜ë„ ë ˆë²¨ ìƒ‰ìƒ */
    .danger-level-low {
        color: #00E676;
    }
    
    .danger-level-medium {
        color: #FFD700;
    }
    
    .danger-level-high {
        color: #FF5252;
    }
    
    /* ì•Œë¦¼ ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
    .stAlert {
        background-color: #2D2D2D;
        color: #E0E0E0;
        border-radius: 10px;
    }
    /* ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìŠ¤íƒ€ì¼ */
    .database-table {
        margin-top: 2rem;
        padding: 1rem;
        background: #2D2D2D;
        border-radius: 15px;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
    }
    
    .database-title {
        text-align: center;
        padding: 1rem;
        background: linear-gradient(135deg, #434343 0%, #000000 100%);
        color: #E0E0E0;
        border-radius: 10px;
        margin-bottom: 1rem;
    }
    
    .stDataFrame {
        background-color: #2D2D2D;
    }
    
    .stDataFrame td, .stDataFrame th {
        color: #E0E0E0 !important;
        background-color: #3D3D3D !important;
    }
    
    .stDataFrame [data-testid="stDataFrameResizeHandle"] {
        background-color: #4D4D4D;
    }
</style>
""", unsafe_allow_html=True)

import re
from collections import defaultdict

def get_or_create_checker_worksheet():
    """checker ì›Œí¬ì‹œíŠ¸ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒì„±"""
    try:
        credentials = {
            "type": "service_account",
            "project_id": st.secrets["gcp_service_account"]["project_id"],
            "private_key_id": st.secrets["gcp_service_account"]["private_key_id"],
            "private_key": st.secrets["gcp_service_account"]["private_key"],
            "client_email": st.secrets["gcp_service_account"]["client_email"],
            "client_id": st.secrets["gcp_service_account"]["client_id"],
            "auth_uri": "https://accounts.google.com/o/oauth2/auth",
            "token_uri": "https://oauth2.googleapis.com/token",
            "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
            "client_x509_cert_url": st.secrets["gcp_service_account"]["client_x509_cert_url"]
        }
        
        SCOPES = [
            'https://www.googleapis.com/auth/spreadsheets',
            'https://www.googleapis.com/auth/drive'
        ]
        
        creds = service_account.Credentials.from_service_account_info(credentials, scopes=SCOPES)
        client = gspread.authorize(creds)
        
        sheet = client.open_by_url('https://docs.google.com/spreadsheets/d/1wPchxwAssBf706VuvxhGp4ESt3vj-N9RLcMaUF075ug/edit?gid=137455637#gid=137455637')
        
        try:
            # checker ì›Œí¬ì‹œíŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹œë„
            checker_sheet = sheet.worksheet('checker')
        except gspread.exceptions.WorksheetNotFound:
            # checker ì›Œí¬ì‹œíŠ¸ê°€ ì—†ìœ¼ë©´ ìƒì„±
            checker_sheet = sheet.add_worksheet('checker', 1000, 2)
            checker_sheet.update('A1:B1', [['ì˜¤ë¥˜', 'ìˆ˜ì •']])
            st.success("'checker' ì›Œí¬ì‹œíŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        return checker_sheet
        
    except Exception as e:
        st.error(f"ì›Œí¬ì‹œíŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

class SheetBasedSpellChecker:
    """êµ¬ê¸€ ì‹œíŠ¸ ê¸°ë°˜ ë§ì¶¤ë²• ê²€ì‚¬ê¸°"""
    
    def __init__(self):
        self.rules = {}  # ì´ˆê¸°í™”
        self.load_rules()  # ê·œì¹™ ë¡œë“œ
        
    def load_rules(self):
        """êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ê·œì¹™ ë¡œë“œ"""
        try:
            checker_sheet = get_or_create_checker_worksheet()
            if not checker_sheet:
                return
            
            # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            data = checker_sheet.get_all_values()
            
            # í—¤ë” ì œì™¸í•˜ê³  ê·œì¹™ ë”•ì…”ë„ˆë¦¬ ìƒì„±
            if len(data) > 1:  # í—¤ë” í–‰ì´ ìˆëŠ” ê²½ìš°
                for row in data[1:]:  # ì²« í–‰(í—¤ë”) ì œì™¸
                    if len(row) >= 2 and row[0] and row[1]:  # Aì—´ê³¼ Bì—´ì´ ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ
                        self.rules[row[0].strip()] = row[1].strip()
            
        except Exception as e:
            st.error(f"ê·œì¹™ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    def check(self, text):
        """í…ìŠ¤íŠ¸ ë§ì¶¤ë²• ê²€ì‚¬ - ì •ê·œì‹ê³¼ ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­ ì§€ì›"""
        if not text or text.isspace():
            return {
                'original': text,
                'corrected': text,
                'corrections': [],
                'error': None
            }
            
        try:
            corrections = []
            corrected_text = text
            
            # ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
            words = re.findall(r'\b\w+\b', text)
            processed_corrections = set()  # ì¤‘ë³µ êµì • ë°©ì§€ìš©
            
            for wrong, right in self.rules.items():
                try:
                    # ì •ê·œì‹ íŒ¨í„´ì¸ì§€ í™•ì¸
                    if wrong.startswith('^') and wrong.endswith('$'):
                        pattern = re.compile(wrong)
                        matches = pattern.finditer(text)
                        
                        for match in matches:
                            matched_text = match.group(0)
                            corrected_word = re.sub(wrong, right, matched_text)
                            
                            if matched_text != corrected_word:
                                correction_key = (matched_text, corrected_word)
                                if correction_key not in processed_corrections:
                                    processed_corrections.add(correction_key)
                                    corrected_text = corrected_text.replace(matched_text, corrected_word)
                                    corrections.append({
                                        'original': matched_text,
                                        'corrected': corrected_word,
                                        'type': 'ë§ì¶¤ë²•/í‘œí˜„ ì˜¤ë¥˜ (ì •ê·œì‹)',
                                        'pattern': wrong,
                                        'replacement': right
                                    })
                    else:
                        # ì¼ë°˜ ë¬¸ìì—´ ë§¤ì¹­ - ë¶€ë¶„ ë¬¸ìì—´ í¬í•¨ ê²€ì‚¬
                        for word in words:
                            if wrong in word:
                                corrected_word = word.replace(wrong, right)
                                correction_key = (word, corrected_word)
                                
                                if word != corrected_word and correction_key not in processed_corrections:
                                    processed_corrections.add(correction_key)
                                    corrected_text = corrected_text.replace(word, corrected_word)
                                    corrections.append({
                                        'original': word,
                                        'corrected': corrected_word,
                                        'type': 'ë§ì¶¤ë²•/í‘œí˜„ ì˜¤ë¥˜',
                                        'pattern': wrong,
                                        'replacement': right
                                    })
                                    
                except re.error:
                    # ì˜ëª»ëœ ì •ê·œì‹ì€ ì¼ë°˜ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
                    if wrong in text:
                        correction_key = (wrong, right)
                        if correction_key not in processed_corrections:
                            processed_corrections.add(correction_key)
                            corrected_text = corrected_text.replace(wrong, right)
                            corrections.append({
                                'original': wrong,
                                'corrected': right,
                                'type': 'ë§ì¶¤ë²•/í‘œí˜„ ì˜¤ë¥˜',
                                'pattern': wrong,
                                'replacement': right
                            })
            
            # êµì • ê²°ê³¼ ì •ë ¬
            corrections.sort(key=lambda x: len(x['original']), reverse=True)
            
            return {
                'original': text,
                'corrected': corrected_text,
                'corrections': corrections,
                'error': None
            }
            
        except Exception as e:
            return {
                'original': text,
                'corrected': text,
                'corrections': [],
                'error': str(e)
            }

    def add_rule(self, wrong, right):
        """ìƒˆë¡œìš´ ë§ì¶¤ë²• ê·œì¹™ ì¶”ê°€"""
        try:
            checker_sheet = get_or_create_checker_worksheet()
            if checker_sheet:
                checker_sheet.append_row([wrong.strip(), right.strip()])
                self.rules[wrong.strip()] = right.strip()
                return True
        except Exception as e:
            st.error(f"ê·œì¹™ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

    def get_rules(self):
        """í˜„ì¬ ë“±ë¡ëœ ëª¨ë“  ê·œì¹™ ë°˜í™˜"""
        return self.rules

def check_with_regex(self, text):
    """í…ìŠ¤íŠ¸ ë§ì¶¤ë²• ê²€ì‚¬ - ì •ê·œì‹ê³¼ ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­ ì§€ì›"""
    if not text or text.isspace():
        return {
            'original': text,
            'corrected': text,
            'corrections': [],
            'error': None
        }
        
    try:
        corrections = []
        corrected_text = text
        
        for wrong, right in self.rules.items():
            try:
                # ì •ê·œì‹ íŒ¨í„´ì¸ì§€ í™•ì¸
                if wrong.startswith('^') and wrong.endswith('$'):
                    # ì •ê·œì‹ íŒ¨í„´ ì ìš©
                    pattern = re.compile(wrong)
                    matches = pattern.finditer(text)
                    
                    for match in matches:
                        matched_text = match.group(0)
                        # ì •ê·œì‹ ê·¸ë£¹ ì°¸ì¡° ì²˜ë¦¬
                        corrected_word = re.sub(wrong, right, matched_text)
                        
                        if matched_text != corrected_word:
                            corrected_text = corrected_text.replace(matched_text, corrected_word)
                            corrections.append({
                                'original': matched_text,
                                'corrected': corrected_word,
                                'type': 'ë§ì¶¤ë²•/í‘œí˜„ ì˜¤ë¥˜ (ì •ê·œì‹)',
                                'pattern': wrong,
                                'replacement': right
                            })
                else:
                    # ì¼ë°˜ ë¬¸ìì—´ ë§¤ì¹­
                    words = re.findall(r'\b\w+\b', text)
                    for word in words:
                        if wrong in word:
                            corrected_word = word.replace(wrong, right)
                            corrected_text = corrected_text.replace(word, corrected_word)
                            corrections.append({
                                'original': word,
                                'corrected': corrected_word,
                                'type': 'ë§ì¶¤ë²•/í‘œí˜„ ì˜¤ë¥˜',
                                'pattern': wrong,
                                'replacement': right
                            })
            except re.error:
                # ì˜ëª»ëœ ì •ê·œì‹ íŒ¨í„´ì€ ì¼ë°˜ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
                if wrong in text:
                    corrected_text = corrected_text.replace(wrong, right)
                    corrections.append({
                        'original': wrong,
                        'corrected': right,
                        'type': 'ë§ì¶¤ë²•/í‘œí˜„ ì˜¤ë¥˜',
                        'pattern': wrong,
                        'replacement': right
                    })
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        unique_corrections = []
        seen = set()
        for corr in corrections:
            key = (corr['original'], corr['corrected'])
            if key not in seen:
                seen.add(key)
                unique_corrections.append(corr)
        
        return {
            'original': text,
            'corrected': corrected_text,
            'corrections': unique_corrections,
            'error': None
        }
        
    except Exception as e:
        return {
            'original': text,
            'corrected': text,
            'corrections': [],
            'error': str(e)
        }


def display_spelling_analysis(spelling_result):
    """ë§ì¶¤ë²• ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    if spelling_result.get('error'):
        st.warning(f"âš ï¸ ë§ì¶¤ë²• ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {spelling_result['error']}")
        return
        
    if not spelling_result['corrections']:
        st.info("âœ… ë§ì¶¤ë²• ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    st.markdown("""
        <div style='background-color: #2D2D2D; padding: 15px; border-radius: 10px; margin: 15px 0;'>
            <h3 style='color: #E0E0E0;'>ğŸ“ ë§ì¶¤ë²• ê²€ì‚¬ ê²°ê³¼</h3>
        </div>
    """, unsafe_allow_html=True)
    
    # ìˆ˜ì • ì‚¬í•­ í‘œì‹œ
    for correction in spelling_result['corrections']:
        st.markdown(f"""
            <div style='background-color: #3D3D3D; padding: 10px; border-radius: 8px; margin: 5px 0;'>
                <p>ğŸ” ìˆ˜ì • ì „: <span style='color: #FF5252;'>{correction['original']}</span></p>
                <p>âœ… ìˆ˜ì • í›„: <span style='color: #00E676;'>{correction['corrected']}</span></p>
            </div>
        """, unsafe_allow_html=True)
    
    # ì „ì²´ í…ìŠ¤íŠ¸ ë¹„êµ
    if spelling_result['original'] != spelling_result['corrected']:
        st.markdown("""
            <div style='background-color: #2D2D2D; padding: 15px; border-radius: 10px; margin-top: 15px;'>
                <h4 style='color: #E0E0E0;'>ğŸ“„ ì „ì²´ í…ìŠ¤íŠ¸ ë¹„êµ</h4>
            </div>
        """, unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**ì›ë¬¸:**")
            st.markdown(f"""
                <div style='background-color: #3D3D3D; padding: 10px; border-radius: 8px;'>
                    {spelling_result['original']}
                </div>
            """, unsafe_allow_html=True)
        with col2:
            st.markdown("**êµì •ë¬¸:**")
            st.markdown(f"""
                <div style='background-color: #3D3D3D; padding: 10px; border-radius: 8px;'>
                    {spelling_result['corrected']}
                </div>
            """, unsafe_allow_html=True)

def analyze_text_with_spelling(input_text, data, threshold=0.7):
    """í…ìŠ¤íŠ¸ ë¶„ì„ê³¼ ë§ì¶¤ë²• ê²€ì‚¬ í†µí•©"""
    
    # ë§ì¶¤ë²• ê²€ì‚¬
    checker = SheetBasedSpellChecker()
    spelling_result = checker.check(input_text)
    
    # íŒ¨í„´ ë§¤ì¹­
    found_patterns = find_matching_patterns(input_text, data, threshold)
    
    # ë§ì¶¤ë²• êµì • í›„ ì¶”ê°€ íŒ¨í„´ ê²€ì‚¬
    if spelling_result['corrections']:
        corrected_patterns = find_matching_patterns(
            spelling_result['corrected'], 
            data, 
            threshold
        )
        
        # ìƒˆë¡œìš´ íŒ¨í„´ ì¶”ê°€
        existing_patterns = {p['pattern'] for p in found_patterns}
        for pattern in corrected_patterns:
            if pattern['pattern'] not in existing_patterns:
                pattern['found_in_corrected'] = True
                found_patterns.append(pattern)
    
    return {
        'patterns': found_patterns,
        'spelling': spelling_result
    }

# 1. ë°ì´í„° ì „ì²˜ë¦¬ ìµœì í™”
@st.cache_data(ttl=3600)
def preprocess_patterns(data):
    """íŒ¨í„´ ë°ì´í„° ì „ì²˜ë¦¬ ë° ìºì‹± - ìµœì í™” ë²„ì „"""
    if not data:
        st.error("ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return {
            'short': [],
            'medium': [],
            'long': []
        }
    
    processed_patterns = []
    
    # ê¸¸ì´ë³„ë¡œ íŒ¨í„´ ë¶„ë¥˜
    short_patterns = []
    medium_patterns = []
    long_patterns = []
    
    try:
        for record in data:
            if not isinstance(record, dict):
                continue
                
            # text í•„ë“œê°€ ì—†ê±°ë‚˜ Noneì¸ ê²½ìš° ê±´ë„ˆë›°ê¸°
            if 'text' not in record or record['text'] is None:
                continue
                
            # ìˆ«ìí˜•ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
            if isinstance(record['text'], (int, float)):
                pattern_text = str(record['text']).lower()
            else:
                try:
                    pattern_text = str(record['text']).lower()
                except:
                    continue
            
            if not pattern_text.strip():  # ë¹ˆ ë¬¸ìì—´ ê±´ë„ˆë›°ê¸°
                continue
                
            try:
                pattern_text_cleaned = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', pattern_text)
                pattern_words = set(w for w in pattern_text_cleaned.split() if w.strip())
                
                processed = {
                    'original': record,
                    'cleaned_text': pattern_text_cleaned,
                    'words': pattern_words,
                    'chars': set(pattern_text_cleaned),
                    'word_count': len(pattern_words),
                    'length': len(pattern_text_cleaned)
                }
                
                # ê¸¸ì´ì— ë”°ë¼ ë¶„ë¥˜
                if processed['length'] <= 10:
                    short_patterns.append(processed)
                elif processed['length'] <= 30:
                    medium_patterns.append(processed)
                else:
                    long_patterns.append(processed)
                    
            except Exception as e:
                st.error(f"íŒ¨í„´ '{pattern_text}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                continue
        
        result = {
            'short': short_patterns,
            'medium': medium_patterns,
            'long': long_patterns
        }
        
        # ê²°ê³¼ ê²€ì¦
        if not any(result.values()):
            st.warning("ì²˜ë¦¬ëœ íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            total_patterns = sum(len(patterns) for patterns in result.values())
            st.success(f"ì´ {total_patterns}ê°œì˜ íŒ¨í„´ì´ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        return result
        
    except Exception as e:
        st.error(f"ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return {
            'short': [],
            'medium': [],
            'long': []
        }

def check_pattern(input_data, pattern_data, threshold=0.7):
    """ë‹¨ì¼ íŒ¨í„´ ë§¤ì¹­ ê²€ì‚¬ - ìµœì í™” ë²„ì „"""
    if not pattern_data or 'chars' not in pattern_data:
        return None
        
    input_text_cleaned, input_words, input_chars = input_data
    
    try:
        # ë¹ ë¥¸ ë¬¸ì ê¸°ë°˜ í•„í„°ë§
        char_intersection = len(input_chars & pattern_data['chars'])
        if char_intersection < min(3, len(pattern_data['chars']) * 0.3):
            return None
        
        # ë‹¨ì–´ ê¸°ë°˜ í•„í„°ë§
        common_words = input_words & pattern_data['words']
        word_match_ratio = len(common_words) / pattern_data['word_count'] if pattern_data['word_count'] > 0 else 0
        
        # ì§§ì€ íŒ¨í„´ì€ í¬í•¨ ì—¬ë¶€ë§Œ ë¹ ë¥´ê²Œ ì²´í¬
        if pattern_data['length'] <= 10:
            if pattern_data['cleaned_text'] in input_text_cleaned:
                similarity = 1.0
            elif word_match_ratio < threshold * 0.5:
                return None
            else:
                similarity = word_match_ratio
        else:
            # ê¸´ íŒ¨í„´ì€ ë‹¨ì–´ ë§¤ì¹­ ë¹„ìœ¨ë¡œ 1ì°¨ í•„í„°ë§
            if word_match_ratio < threshold * 0.5:
                return None
            similarity = difflib.SequenceMatcher(None, input_text_cleaned, pattern_data['cleaned_text']).ratio()
        
        if similarity >= threshold:
            record = pattern_data['original']
            try:
                # ìˆ«ìí˜• ìœ„í—˜ë„ ì²˜ë¦¬
                danger_level = str(record.get('dangerlevel', '0'))
                if danger_level.isdigit():
                    danger_level = int(danger_level)
                else:
                    danger_level = 0
            except (ValueError, TypeError):
                danger_level = 0
                
            return {
                'pattern': str(record['text']),
                'analysis': str(record.get('output', '')),
                'danger_level': danger_level,
                'url': str(record.get('url', '')),
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'match_score': similarity
            }
        
        return None
        
    except Exception as e:
        st.error(f"íŒ¨í„´ ë§¤ì¹­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None



@st.cache_data(ttl=300)
def load_sheet_data():
    """Google Sheets ë°ì´í„° ë¡œë“œ"""
    try:
        credentials = {
            "type": "service_account",
            "project_id": st.secrets["gcp_service_account"]["project_id"],
            "private_key_id": st.secrets["gcp_service_account"]["private_key_id"],
            "private_key": st.secrets["gcp_service_account"]["private_key"],
            "client_email": st.secrets["gcp_service_account"]["client_email"],
            "client_id": st.secrets["gcp_service_account"]["client_id"],
            "auth_uri": "https://accounts.google.com/o/oauth2/auth",
            "token_uri": "https://oauth2.googleapis.com/token",
            "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
            "client_x509_cert_url": st.secrets["gcp_service_account"]["client_x509_cert_url"],
            "universe_domain": "googleapis.com"
        }
        
        SCOPES = [
            'https://www.googleapis.com/auth/spreadsheets',
            'https://www.googleapis.com/auth/drive'
        ]
        
        creds = service_account.Credentials.from_service_account_info(
            credentials, scopes=SCOPES)
        client = gspread.authorize(creds)
        
        sheet = client.open_by_url('https://docs.google.com/spreadsheets/d/1wPchxwAssBf706VuvxhGp4ESt3vj-N9RLcMaUF075ug/edit?gid=137455637#gid=137455637')
        worksheet = sheet.get_worksheet(0)
        return worksheet.get_all_records()
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

@st.cache_resource
def get_sheet_instance():
    """ì‹œíŠ¸ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    try:
        credentials = {
            "type": "service_account",
            "project_id": st.secrets["gcp_service_account"]["project_id"],
            "private_key_id": st.secrets["gcp_service_account"]["private_key_id"],
            "private_key": st.secrets["gcp_service_account"]["private_key"],
            "client_email": st.secrets["gcp_service_account"]["client_email"],
            "client_id": st.secrets["gcp_service_account"]["client_id"],
            "auth_uri": "https://accounts.google.com/o/oauth2/auth",
            "token_uri": "https://oauth2.googleapis.com/token",
            "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
            "client_x509_cert_url": st.secrets["gcp_service_account"]["client_x509_cert_url"],
            "universe_domain": "googleapis.com"
        }
        
        SCOPES = [
            'https://www.googleapis.com/auth/spreadsheets',
            'https://www.googleapis.com/auth/drive'
        ]
        
        creds = service_account.Credentials.from_service_account_info(
            credentials, scopes=SCOPES)
        client = gspread.authorize(creds)
        
        sheet = client.open_by_url('https://docs.google.com/spreadsheets/d/1wPchxwAssBf706VuvxhGp4ESt3vj-N9RLcMaUF075ug/edit?gid=137455637#gid=137455637')
        return sheet.get_worksheet(0)
    except Exception as e:
        st.error(f"ì‹œíŠ¸ ì—°ê²° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None


# ìµœìƒìœ„ ë ˆë²¨ì— get_color_style í•¨ìˆ˜ ì •ì˜
def get_color_style(score):
    """ìœ„í—˜ë„ ì ìˆ˜ì— ë”°ë¥¸ ìƒ‰ìƒ ìŠ¤íƒ€ì¼ ë°˜í™˜"""
    if score >= 70:
        return "color: #FF5252; font-weight: bold;"  # ë¹¨ê°„ìƒ‰
    elif score >= 30:
        return "color: #FFD700; font-weight: bold;"  # ë…¸ë€ìƒ‰
    else:
        return "color: #00E676; font-weight: bold;"  # ì´ˆë¡ìƒ‰


def calculate_danger_score(matches):
    """ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°"""
    total_score = 0
    for match in matches:
        total_score += match.get('danger_level', 0)
    return total_score

def get_danger_level_class(score):
    """ìœ„í—˜ë„ ì ìˆ˜ì— ë”°ë¥¸ CSS í´ë˜ìŠ¤ ë°˜í™˜"""
    if score < 30:
        return "danger-level-low"
    elif score < 70:
        return "danger-level-medium"
    else:
        return "danger-level-high"

def get_youtube_thumbnail(url):
    """ìœ íŠœë¸Œ URLì—ì„œ ì¸ë„¤ì¼ URL ì¶”ì¶œ"""
    if not url:
        return None
    video_id = re.search(r"(?:v=|\/)([0-9A-Za-z_-]{11}).*", url)
    if video_id and 'youtube.com' in url:
        return f"https://img.youtube.com/vi/{video_id.group(1)}/hqdefault.jpg"
    return None

# 3. ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
def find_matching_patterns(input_text, data, threshold=0.7):
    """í…ìŠ¤íŠ¸ íŒ¨í„´ ë§¤ì¹­ - ì˜¤íƒˆì ë° ë„ì–´ì“°ê¸° ê²€ì‚¬ ì¶”ê°€"""
    if not data or not input_text:
        return []
        
    input_text = str(input_text).strip()
    if not input_text or input_text.isspace():
        return []
    
    try:
        # í•œê¸€ ìëª¨ìŒ ë¶„ë¦¬ í•¨ìˆ˜
        def decompose_hangul(text):
            result = []
            for char in text:
                if 'ê°€' <= char <= 'í£':
                    # í•œê¸€ ìœ ë‹ˆì½”ë“œ ë¶„í•´
                    code = ord(char) - 0xAC00
                    jong = code % 28
                    jung = ((code - jong) // 28) % 21
                    cho = ((code - jong) // 28) // 21
                    result.append((cho, jung, jong))
                else:
                    result.append(char)
            return result

        # ìëª¨ìŒ ìœ ì‚¬ë„ ê³„ì‚°
        def jamo_similarity(char1, char2):
            if isinstance(char1, tuple) and isinstance(char2, tuple):
                # ì´ˆì„±, ì¤‘ì„±, ì¢…ì„± ê°ê° ë¹„êµ
                matches = sum(1 for i in range(3) if char1[i] == char2[i])
                return matches / 3
            return 1.0 if char1 == char2 else 0.0

        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        input_text_cleaned = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', input_text.lower())
        input_jamos = decompose_hangul(input_text_cleaned)
        input_words = set(w for w in input_text_cleaned.split() if w.strip())
        
        # íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼ ì €ì¥
        found_patterns = []
        
        for pattern in data:
            try:
                if not isinstance(pattern, dict) or 'text' not in pattern:
                    continue
                    
                pattern_text = str(pattern['text']).lower()
                pattern_cleaned = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', pattern_text)
                pattern_jamos = decompose_hangul(pattern_cleaned)
                pattern_words = set(pattern_cleaned.split())
                
                if not pattern_words:
                    continue
                
                # ìëª¨ìŒ ìœ ì‚¬ë„ ê³„ì‚°
                jamo_scores = []
                for i in range(len(input_jamos)):
                    for j in range(len(pattern_jamos)):
                        score = jamo_similarity(input_jamos[i], pattern_jamos[j])
                        if score > 0.6:  # ìëª¨ìŒ ìœ ì‚¬ë„ ì„ê³„ê°’
                            jamo_scores.append(score)
                
                # ë‹¨ì–´ ë‹¨ìœ„ ë§¤ì¹­
                word_scores = []
                for input_word in input_words:
                    input_word_jamos = decompose_hangul(input_word)
                    for pattern_word in pattern_words:
                        pattern_word_jamos = decompose_hangul(pattern_word)
                        # ë‹¨ì–´ ê¸¸ì´ê°€ ë¹„ìŠ·í•œ ê²½ìš°ë§Œ ë¹„êµ
                        if abs(len(input_word_jamos) - len(pattern_word_jamos)) <= 2:
                            similarity = sum(jamo_similarity(a, b) for a, b in 
                                          zip(input_word_jamos, pattern_word_jamos)) / max(len(input_word_jamos), len(pattern_word_jamos))
                            if similarity > 0.7:
                                word_scores.append(similarity)
                
                # ìµœì¢… ìœ ì‚¬ë„ ê³„ì‚°
                if word_scores or jamo_scores:
                    avg_word_score = sum(word_scores) / len(word_scores) if word_scores else 0
                    avg_jamo_score = sum(jamo_scores) / len(jamo_scores) if jamo_scores else 0
                    final_score = (avg_word_score * 0.7 + avg_jamo_score * 0.3)
                    
                    if final_score >= threshold:
                        try:
                            danger_level = int(pattern.get('dangerlevel', 0))
                        except (ValueError, TypeError):
                            danger_level = 0
                            
                        # ì˜¤íƒˆì ë° ë„ì–´ì“°ê¸° ì˜¤ë¥˜ í™•ì¸
                        spelling_errors = []
                        spacing_errors = []
                        
                        # ë‹¨ì–´ë³„ ìœ ì‚¬ë„ ìƒì„¸ ë¶„ì„
                        for input_word in input_words:
                            closest_match = None
                            max_similarity = 0
                            
                            for pattern_word in pattern_words:
                                similarity = difflib.SequenceMatcher(None, input_word, pattern_word).ratio()
                                if 0.6 <= similarity < 1.0 and similarity > max_similarity:
                                    closest_match = pattern_word
                                    max_similarity = similarity
                            
                            if closest_match:
                                spelling_errors.append((input_word, closest_match))
                        
                        found_pattern = {
                            'pattern': pattern['text'],
                            'analysis': pattern.get('output', 'ë¶„ì„ ì •ë³´ ì—†ìŒ'),
                            'danger_level': danger_level,
                            'url': pattern.get('url', ''),
                            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            'match_score': final_score,
                            'original_text': input_text,
                            'matched_keywords': sorted(set(word_scores)),
                            'spelling_errors': spelling_errors,
                            'spacing_errors': spacing_errors
                        }
                        
                        if pattern.get('url') and 'youtube.com' in pattern['url']:
                            found_pattern['thumbnail'] = get_youtube_thumbnail(pattern['url'])
                            
                        found_patterns.append(found_pattern)
            
            except Exception as e:
                st.error(f"íŒ¨í„´ '{pattern.get('text', 'ì•Œ ìˆ˜ ì—†ëŠ” íŒ¨í„´')}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                continue
        
        # ë§¤ì¹˜ ì ìˆ˜ì™€ ìœ„í—˜ë„ë¡œ ì •ë ¬
        found_patterns.sort(key=lambda x: (-x['match_score'], -x['danger_level']))
        
        return found_patterns
        
    except Exception as e:
        st.error(f"íŒ¨í„´ ë§¤ì¹­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return []

def extract_keywords(text):
    """í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    try:
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì†Œë¬¸ì ë³€í™˜
        cleaned = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', str(text).lower())
        # 2ê¸€ì ì´ìƒ ë‹¨ì–´ë§Œ ì¶”ì¶œ
        words = [w for w in cleaned.split() if len(w) >= 2]
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        return sorted(set(words))
    except Exception as e:
        st.error(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

def highlight_pattern_in_text(original_text, pattern):
    """í…ìŠ¤íŠ¸ ë‚´ì˜ íŒ¨í„´ì„ í•˜ì´ë¼ì´íŠ¸"""
    try:
        # íŒ¨í„´ê³¼ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”
        pattern_cleaned = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', str(pattern).lower())
        text_cleaned = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', str(original_text).lower())
        
        # CSS ìŠ¤íƒ€ì¼ì´ ì ìš©ëœ í•˜ì´ë¼ì´íŠ¸ HTML
        highlight_style = """
            background: linear-gradient(104deg, rgba(255, 178, 15, 0.1) 0.9%, rgba(255, 178, 15, 0.3) 2.4%, rgba(255, 178, 15, 0.2) 5.8%, rgba(255, 178, 15, 0.1) 93%, rgba(255, 178, 15, 0.1) 96%);
            border-radius: 4px;
            padding: 0.1em 0.2em;
            box-decoration-break: clone;
            -webkit-box-decoration-break: clone;
            position: relative;
            color: #FFB20F;
            font-weight: 500;
        """
        
        # íŒ¨í„´ì˜ ê° ë‹¨ì–´ì— ëŒ€í•´ í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬
        result_text = str(original_text)
        pattern_words = [w for w in pattern_cleaned.split() if len(w) >= 2]
        
        for word in pattern_words:
            # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ë§¤ì¹­í•˜ë˜, ì›ë³¸ í…ìŠ¤íŠ¸ì˜ ëŒ€ì†Œë¬¸ìëŠ” ìœ ì§€
            pattern = re.compile(re.escape(word), re.IGNORECASE)
            result_text = pattern.sub(
                lambda m: f'<span style="{highlight_style}">{m.group()}</span>',
                result_text
            )
        
        return result_text
    except Exception as e:
        st.error(f"í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return str(original_text)

# CSS ìŠ¤íƒ€ì¼ ì¶”ê°€
st.markdown("""
<style>
    /* í•˜ì´ë¼ì´íŠ¸ ê´€ë ¨ ìŠ¤íƒ€ì¼ */
    .highlighted-text {
        font-size: 1.1em;
        line-height: 1.6;
    }
    
    /* ê¸°ì¡´ ìŠ¤íƒ€ì¼ì— ì¶”ê°€ */
    .analysis-card {
        position: relative;
        overflow: hidden;
    }
    
    .analysis-card::before {
        content: '';
        position: absolute;
        left: 0;
        top: 0;
        height: 100%;
        width: 4px;
        background: linear-gradient(to bottom, #FFB20F, #FF9800);
    }
</style>
""", unsafe_allow_html=True)


import streamlit as st
import html

def analyze_file_contents(file_content, data):
    """íŒŒì¼ ë‚´ìš© ë¶„ì„ - ì´ˆê³ ì† ë²„ì „ (í´ë” ë° íƒ€ì… ì²´í¬ ì§€ì›)"""
    import time
    from collections import defaultdict
    import numpy as np
    import zipfile
    import io
    
    if file_content is not None:
        try:
            start_time = time.time()
            
            # ë¡œê·¸ ì»¨í…Œì´ë„ˆ ìƒì„±
            log_container = st.empty()
            def update_log(message, filename=""):
                prefix = f"[{filename}] " if filename else ""
                log_container.markdown(f"""
                    <div style="background-color: #2D2D2D; padding: 10px; border-radius: 5px; margin: 5px 0;">
                        {prefix}{message}
                    </div>
                """, unsafe_allow_html=True)

            # íŒŒì¼ ë¡œë“œ ìµœì í™”
            dfs = []
            filename = getattr(file_content, 'name', 'ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼')
            update_log("ğŸ“‚ íŒŒì¼ ë¡œë”© ë° íŒ¨í„´ ìµœì í™” ì¤‘...", filename)
            
            if hasattr(file_content, 'name'):  # ë‹¨ì¼ íŒŒì¼
                file_type = file_content.name.split('.')[-1].lower()
                if file_type == 'csv':
                    df = pd.read_csv(file_content, dtype=str)
                    df['source_file'] = file_content.name
                    dfs.append(df)
                elif file_type in ['xlsx', 'xls']:
                    df = pd.read_excel(file_content, dtype=str)
                    df['source_file'] = file_content.name
                    dfs.append(df)
                elif file_type == 'zip':  # ZIP íŒŒì¼(í´ë”) ì²˜ë¦¬
                    with zipfile.ZipFile(file_content) as z:
                        for zip_filename in z.namelist():
                            if zip_filename.endswith(('.csv', '.xlsx', '.xls')):
                                with z.open(zip_filename) as f:
                                    if zip_filename.endswith('.csv'):
                                        df = pd.read_csv(io.BytesIO(f.read()), dtype=str)
                                    else:
                                        df = pd.read_excel(io.BytesIO(f.read()), dtype=str)
                                    df['source_file'] = zip_filename
                                    dfs.append(df)

            if not dfs:
                update_log(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì´ê±°ë‚˜ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.", filename)
                return None
                
            update_log(f"ğŸ” {len(dfs)}ê°œì˜ íŒŒì¼ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.", filename)
            
            # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ ë³‘í•©
            df = pd.concat(dfs, ignore_index=True)

            # íŒ¨í„´ ë°ì´í„° ì „ì²˜ë¦¬ ë° ìµœì í™”
            pattern_lookup = defaultdict(list)
            for idx, item in enumerate(data):
                pattern_text = str(item.get('text', '')).lower()
                words = set(re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', pattern_text).split())
                
                # ê° ë‹¨ì–´ë¥¼ í‚¤ë¡œ ì‚¬ìš©í•˜ì—¬ íŒ¨í„´ ì¸ë±ìŠ¤ ì €ì¥
                for word in words:
                    if len(word) >= 2:
                        pattern_lookup[word].append((idx, words))

            update_log("ğŸš€ ì´ˆê³ ì† ë¶„ì„ ì‹œì‘...", filename)

            # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì²˜ë¦¬
            text_columns = df.select_dtypes(include=['object']).columns
            total_patterns_found = 0
            all_results = []
            
            progress_bar = st.progress(0)
            progress_text = st.empty()
            
            def analyze_text_batch(texts, batch_idx, total_batches, source_file):
                """í…ìŠ¤íŠ¸ ë°°ì¹˜ ê³ ì† ë¶„ì„"""
                batch_results = []
                potential_matches = defaultdict(set)
                
                # 1ë‹¨ê³„: ë¹ ë¥¸ í‚¤ì›Œë“œ ë§¤ì¹­
                for text_idx, text in enumerate(texts):
                    # ìˆ«ìí˜• ë°ì´í„° ì²˜ë¦¬
                    if isinstance(text, (int, float)):
                        text = str(text)
                    # None ê°’ ì²˜ë¦¬    
                    if not isinstance(text, str):
                        continue
                        
                    text_lower = text.lower()
                    words = set(re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', text_lower).split())
                    
                    # ê° ë‹¨ì–´ì— ëŒ€í•´ ê°€ëŠ¥í•œ íŒ¨í„´ ì°¾ê¸°
                    for word in words:
                        if len(word) >= 2 and word in pattern_lookup:
                            for pattern_idx, pattern_words in pattern_lookup[word]:
                                potential_matches[text_idx].add(pattern_idx)
                
                # 2ë‹¨ê³„: ì •í™•í•œ ë§¤ì¹­ ê²€ì‚¬
                for text_idx, pattern_indices in potential_matches.items():
                    text = texts[text_idx]
                    if isinstance(text, (int, float)):
                        text = str(text)
                    text_lower = text.lower()
                    text_words = set(re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', text_lower).split())
                    
                    for pattern_idx in pattern_indices:
                        pattern_item = data[pattern_idx]
                        pattern_text = str(pattern_item['text']).lower()
                        pattern_words = set(re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', pattern_text).split())
                        
                        # ì›Œë“œ ë§¤ì¹­ ìŠ¤ì½”ì–´ ê³„ì‚°
                        common_words = text_words & pattern_words
                        if common_words:
                            match_score = len(common_words) / len(pattern_words)
                            if match_score >= 0.7:  # ì„ê³„ê°’
                                try:
                                    danger_level = int(pattern_item.get('dangerlevel', 0))
                                except (ValueError, TypeError):
                                    danger_level = 0
                                    
                                batch_results.append({
                                    'text': text,
                                    'pattern': pattern_item['text'],
                                    'analysis': pattern_item['output'],
                                    'danger_level': danger_level,
                                    'url': pattern_item.get('url', ''),
                                    'match_score': match_score,
                                    'source_file': source_file
                                })
                
                return batch_results

            # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°°ì¹˜ ì²˜ë¦¬
            total_rows = df[text_columns].notna().sum().sum()
            processed_rows = 0
            batch_size = 5000  # ëŒ€ìš©ëŸ‰ ë°°ì¹˜
            
            for col_idx, col in enumerate(text_columns):
                if col == 'source_file':  # source_file ì»¬ëŸ¼ ì œì™¸
                    continue
                    
                texts = df[col].dropna().tolist()
                source_files = df.loc[df[col].notna(), 'source_file'].tolist()
                total_batches = (len(texts) + batch_size - 1) // batch_size
                
                for batch_idx in range(total_batches):
                    start_idx = batch_idx * batch_size
                    end_idx = min((batch_idx + 1) * batch_size, len(texts))
                    batch_texts = texts[start_idx:end_idx]
                    batch_sources = source_files[start_idx:end_idx]
                    
                    # ë°°ì¹˜ ë¶„ì„
                    for text, source_file in zip(batch_texts, batch_sources):
                        results = analyze_text_batch([text], 0, 1, source_file)
                        if results:
                            # ì»¬ëŸ¼ ì •ë³´ ì¶”ê°€
                            for r in results:
                                r['column'] = col
                            all_results.extend(results)
                            total_patterns_found += len(results)
                    
                    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                    processed_rows += len(batch_texts)
                    progress = min(processed_rows / total_rows, 1.0)
                    progress_bar.progress(progress)
                    
                    if batch_idx % 2 == 0:  # ë¡œê·¸ ì—…ë°ì´íŠ¸ ë¹ˆë„ ì¡°ì ˆ
                        elapsed_time = time.time() - start_time
                        speed = processed_rows / elapsed_time if elapsed_time > 0 else 0
                        update_log(f"""
                            ğŸ“Š ë¶„ì„ ì§„í–‰ ì¤‘:
                            - ì²˜ë¦¬ ì†ë„: {speed:.0f} í–‰/ì´ˆ
                            - ì²˜ë¦¬ëœ í–‰: {processed_rows:,}/{total_rows:,}
                            - ë°œê²¬ëœ íŒ¨í„´: {total_patterns_found:,}ê°œ
                        """, filename)
            
            # ìµœì¢… ê²°ê³¼ ì •ë¦¬
            progress_bar.empty()
            progress_text.empty()
            
            if all_results:
                # ìµœì¢… ì •ë ¬ ë° ì¤‘ë³µ ì œê±°
                seen = set()
                unique_results = []
                for r in sorted(all_results, key=lambda x: (-x['match_score'], -x['danger_level'])):
                    key = (r['text'], r['pattern'], r['source_file'])
                    if key not in seen:
                        seen.add(key)
                        unique_results.append(r)
                
                total_time = time.time() - start_time
                update_log(f"""
                    âš ï¸ ë¶„ì„ ì™„ë£Œ:
                    - ì²˜ë¦¬ ì‹œê°„: {total_time:.1f}ì´ˆ
                    - ì²˜ë¦¬ ì†ë„: {total_rows/total_time:.0f} í–‰/ì´ˆ
                    - ì´ ì²˜ë¦¬ëœ í–‰: {processed_rows:,}ê°œ
                    - ë°œê²¬ëœ íŒ¨í„´: {total_patterns_found:,}ê°œ
                """, filename)
                
                return {
                    'total_patterns': len(unique_results),
                    'results': unique_results[:1000],
                    'filename': filename
                }
            else:
                update_log(f"âœ… {filename}ì—ì„œ ë°œê²¬ëœ íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
        except Exception as e:
            st.error(f"'{filename}' íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            import traceback
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return None
    return None

def group_similar_patterns(pattern_results, similarity_threshold=0.9):
    """ìœ ì‚¬í•œ íŒ¨í„´ë“¤ì„ ê·¸ë£¹í™”"""
    grouped_results = []
    used_indices = set()
    
    for i, result in enumerate(pattern_results):
        if i in used_indices:
            continue
            
        # í˜„ì¬ íŒ¨í„´ê³¼ ìœ ì‚¬í•œ íŒ¨í„´ë“¤ì„ ì°¾ì•„ ê·¸ë£¹í™”
        similar_patterns = []
        base_pattern = result['pattern']
        base_text = result['text']
        
        for j, other_result in enumerate(pattern_results):
            if j <= i:  # ì´ë¯¸ ì²˜ë¦¬ëœ íŒ¨í„´ì€ ê±´ë„ˆë›°ê¸°
                continue
                
            # íŒ¨í„´ ìœ ì‚¬ë„ ê²€ì‚¬
            pattern_similarity = difflib.SequenceMatcher(None, base_pattern, other_result['pattern']).ratio()
            text_similarity = difflib.SequenceMatcher(None, base_text, other_result['text']).ratio()
            
            if pattern_similarity >= similarity_threshold or text_similarity >= similarity_threshold:
                similar_patterns.append(other_result)
                used_indices.add(j)
        
        if similar_patterns:
            # ê·¸ë£¹ ëŒ€í‘œ íŒ¨í„´ ì„ íƒ (ìœ„í—˜ë„ê°€ ê°€ì¥ ë†’ì€ ê²ƒ)
            all_patterns = [result] + similar_patterns
            representative = max(all_patterns, key=lambda x: (x['danger_level'], x['match_score']))
            
            # ê·¸ë£¹ ì •ë³´ ì¶”ê°€
            representative['similar_count'] = len(similar_patterns)
            representative['similar_patterns'] = similar_patterns
            grouped_results.append(representative)
        else:
            grouped_results.append(result)
            
    return grouped_results

def display_file_analysis_results(analysis_results):
    """íŒŒì¼ ë¶„ì„ ê²°ê³¼ í‘œì‹œ - ê·¸ë£¹í™”ëœ íŒ¨í„´ê³¼ ë§ì¶¤ë²• ê²€ì‚¬ í¬í•¨"""
    try:
        if not analysis_results or not analysis_results['results']:
            filename = analysis_results.get('filename', 'ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼') if analysis_results else 'ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼'
            st.warning(f"ğŸ” '{filename}'ì—ì„œ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        results = analysis_results['results']
        
        # ê²°ê³¼ ë¶„ë¦¬
        pattern_results = [r for r in results if not r.get('is_spell_check')]
        spell_check_results = [r for r in results if r.get('is_spell_check')]
        
        # íŒ¨í„´ ê²°ê³¼ ê·¸ë£¹í™”
        grouped_pattern_results = group_similar_patterns(pattern_results)
        
        # í†µê³„ ê³„ì‚°
        total_score = sum(result['danger_level'] for result in pattern_results)
        avg_score = total_score / len(pattern_results) if pattern_results else 0
        high_risk_count = sum(1 for r in pattern_results if r['danger_level'] >= 70)
        
        # ìš”ì•½ í†µê³„ í‘œì‹œ
        st.markdown("""
            <div style='background-color: #2D2D2D; padding: 15px; border-radius: 10px; margin-bottom: 20px;'>
                <h3 style='color: #E0E0E0; margin-bottom: 10px;'>ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½</h3>
            </div>
        """, unsafe_allow_html=True)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ìœ„í—˜ íŒ¨í„´", f"{len(grouped_pattern_results)}ê°œ")
        with col2:
            st.metric("í‰ê·  ìœ„í—˜ë„", f"{avg_score:.1f}")
        with col3:
            st.metric("ê³ ìœ„í—˜ íŒ¨í„´", f"{high_risk_count}ê°œ")
        with col4:
            st.metric("ë§ì¶¤ë²• ì˜¤ë¥˜", f"{len(spell_check_results)}ê°œ")

        # íƒ­ìœ¼ë¡œ ê²°ê³¼ êµ¬ë¶„
        tab1, tab2 = st.tabs(["âš ï¸ ìœ„í—˜ íŒ¨í„´", "ğŸ“ ë§ì¶¤ë²• ì˜¤ë¥˜"])
        
        with tab1:
            if grouped_pattern_results:
                # íŒŒì¼ë³„ ê·¸ë£¹í™”
                file_groups = {}
                for result in grouped_pattern_results:
                    source_file = result.get('source_file', 'ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼')
                    if source_file not in file_groups:
                        file_groups[source_file] = {'high': [], 'medium': [], 'low': []}
                    
                    if result['danger_level'] >= 70:
                        file_groups[source_file]['high'].append(result)
                    elif result['danger_level'] >= 30:
                        file_groups[source_file]['medium'].append(result)
                    else:
                        file_groups[source_file]['low'].append(result)

                # íŒŒì¼ë³„ë¡œ ê²°ê³¼ í‘œì‹œ
                for source_file, severity_groups in file_groups.items():
                    st.markdown(f"""
                        <h2 style='color:#E0E0E0; border-bottom: 2px solid #555555; padding-bottom: 10px; margin-top: 30px;'>
                            ğŸ“„ {html.escape(source_file)}
                        </h2>
                    """, unsafe_allow_html=True)

                    severity_info = [
                        ('high', 'ğŸš¨ ê³ ìœ„í—˜ í•­ëª©', "#FF5252"),
                        ('medium', 'âš ï¸ ì£¼ì˜ í•­ëª©', "#FFD700"),
                        ('low', 'âœ… ì•ˆì „ í•­ëª©', "#00E676")
                    ]

                    for severity, title, border_color in severity_info:
                        results_by_severity = severity_groups[severity]
                        if not results_by_severity:
                            continue

                        st.markdown(f"""
                            <h3 style='color:{border_color}; border-left: 6px solid {border_color}; padding-left: 10px; margin-top: 20px;'>
                                {title} ({len(results_by_severity)}ê°œ)
                            </h3>
                        """, unsafe_allow_html=True)

                        for result in results_by_severity:
                            match_percentage = int(result['match_score'] * 100)
                            similar_count = result.get('similar_count', 0)

                            with st.container():
                                # ê¸°ë³¸ ì •ë³´ í‘œì‹œ
                                cols = st.columns([2, 1, 1])
                                with cols[0]:
                                    st.markdown(f"<p style='color:#FFFFFF;'><strong>ìœ„í—˜ë„:</strong> <span style='color:{border_color}; font-weight:bold;'>{result['danger_level']}</span></p>", unsafe_allow_html=True)
                                with cols[1]:
                                    st.markdown(f"<p style='color:#FFFFFF;'><strong>ì¼ì¹˜ìœ¨:</strong> {match_percentage}%</p>", unsafe_allow_html=True)
                                with cols[2]:
                                    if similar_count > 0:
                                        st.markdown(f"<p style='color:#FFFFFF;'><strong>ìœ ì‚¬ íŒ¨í„´:</strong> {similar_count}ê°œ</p>", unsafe_allow_html=True)

                                # ì›ë³¸ í…ìŠ¤íŠ¸ í‘œì‹œ
                                st.markdown("<div style='font-weight:bold; margin-top: 10px; color: #FFFFFF;'>ëŒ€í‘œ í…ìŠ¤íŠ¸:</div>", unsafe_allow_html=True)
                                try:
                                    highlighted_text = highlight_pattern_in_text(result['text'], result['pattern'])
                                    st.markdown(f"<div style='white-space: pre-wrap; font-family: \"Noto Sans KR\", sans-serif; background-color: #333333; padding: 10px; border-radius: 5px; color: #FFFFFF;'>{highlighted_text}</div>", unsafe_allow_html=True)
                                except:
                                    st.markdown(f"<div style='white-space: pre-wrap; font-family: \"Noto Sans KR\", sans-serif; background-color: #333333; padding: 10px; border-radius: 5px; color: #FFFFFF;'>{html.escape(str(result['text']))}</div>", unsafe_allow_html=True)

                                # ìœ ì‚¬ íŒ¨í„´ì´ ìˆëŠ” ê²½ìš° í™•ì¥ ê°€ëŠ¥í•œ ì„¹ì…˜ìœ¼ë¡œ í‘œì‹œ
                                if similar_count > 0:
                                    with st.expander(f"ìœ ì‚¬í•œ íŒ¨í„´ {similar_count}ê°œ ë³´ê¸°"):
                                        for similar in result['similar_patterns']:
                                            st.markdown(f"""
                                                <div style='background-color: #2D2D2D; padding: 10px; border-radius: 5px; margin: 5px 0;'>
                                                    <p style='color: #E0E0E0;'>{html.escape(str(similar['text']))}</p>
                                                    <p style='color: #888888; font-size: 0.9em;'>ì¼ì¹˜ìœ¨: {int(similar['match_score'] * 100)}%</p>
                                                </div>
                                            """, unsafe_allow_html=True)

                                # íŒ¨í„´ ì •ë³´ í‘œì‹œ
                                st.markdown("<div style='font-weight:bold; margin-top: 10px; color: #FFFFFF;'>ë§¤ì¹­ëœ íŒ¨í„´:</div>", unsafe_allow_html=True)
                                st.markdown(f"<div style='background-color: #444444; padding: 8px; border-radius: 5px; color: #FFFFFF;'>{html.escape(str(result['pattern']))}</div>", unsafe_allow_html=True)

                                # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                                st.markdown("<div style='font-weight:bold; margin-top: 10px; color: #FFFFFF;'>ë¶„ì„:</div>", unsafe_allow_html=True)
                                st.markdown(f"<div style='background-color: rgba{tuple(int(border_color[i:i+2], 16) for i in (1, 3, 5))}, 0.1); padding: 10px; border-radius: 5px; color: #FFFFFF;'>{html.escape(str(result['analysis']))}</div>", unsafe_allow_html=True)

                                # ì°¸ê³  ìë£Œ ë§í¬
                                if result.get("url"):
                                    with st.container():
                                        thumbnail_url = get_youtube_thumbnail(result["url"])
                                        if thumbnail_url:
                                            try:
                                                response = requests.get(thumbnail_url)
                                                image = Image.open(BytesIO(response.content))
                                                st.image(image, width=200, use_column_width=False)
                                            except:
                                                pass
                                        st.markdown(f"<p><strong>ğŸ”— <a href='{html.escape(result['url'])}' target='_blank' style='color:{border_color};'>ì°¸ê³  ìë£Œ</a></strong></p>", unsafe_allow_html=True)

                            st.markdown("<hr style='border: none; height: 1px; background-color: #555555;'>", unsafe_allow_html=True)
            else:
                st.info("ìœ„í—˜ íŒ¨í„´ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # ë§ì¶¤ë²• ê²€ì‚¬ ê²°ê³¼ í‘œì‹œ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
        with tab2:
            if spell_check_results:
                # ... (ê¸°ì¡´ì˜ ë§ì¶¤ë²• ê²€ì‚¬ ê²°ê³¼ í‘œì‹œ ì½”ë“œ ìœ ì§€)
                pass
            else:
                st.info("ë§ì¶¤ë²• ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    except Exception as e:
        st.error(f"ê²°ê³¼ í‘œì‹œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

def get_thumbnail_url(url):
    """URLì—ì„œ ì¸ë„¤ì¼ URL ì¶”ì¶œ"""
    if not url:
        return None
    
    # ìœ íŠœë¸Œ URL ì²˜ë¦¬
    video_id = re.search(r"(?:v=|\/)([0-9A-Za-z_-]{11}).*", url)
    if video_id and 'youtube.com' in url:
        return f"https://img.youtube.com/vi/{video_id.group(1)}/hqdefault.jpg"
    
    # ê¸°íƒ€ URL ì²˜ë¦¬
    try:
        response = requests.get(url)
        if 'image/' in response.headers.get('content-type', ''):
            return url
    except:
        pass
    
    return None


# ì¶”ê°€ CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    /* í•˜ì´ë¼ì´íŠ¸ ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼ */
    .highlight-container {
        background-color: #2D2D2D;
        padding: 15px;
        border-radius: 10px;
        margin: 10px 0;
    }
    
    /* íŒŒì¼ ë¶„ì„ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .file-analysis-card {
        background-color: #2D2D2D;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
        border-left: 4px solid transparent;
    }
    
    /* í…ìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼ */
    .text-container {
        background-color: #3D3D3D;
        padding: 15px;
        border-radius: 8px;
        margin: 10px 0;
        line-height: 1.6;
        font-family: 'Noto Sans KR', sans-serif;
    }
</style>
""", unsafe_allow_html=True)

def display_analysis_results(patterns, total_score):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ - ê°œì„ ëœ ë²„ì „"""
    try:
        # ì „ì²´ ìœ„í—˜ë„ í‘œì‹œ
        danger_level_class = get_danger_level_class(total_score)
        st.markdown("""
            <div style='background-color: #2D2D2D; padding: 15px; border-radius: 10px; margin: 15px 0;'>
                <h3 style='color: #E0E0E0; margin-bottom: 10px;'>ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½</h3>
            </div>
        """, unsafe_allow_html=True)

        # ìš”ì•½ í†µê³„
        high_risk = sum(1 for p in patterns if p['danger_level'] >= 70)
        medium_risk = sum(1 for p in patterns if 30 <= p['danger_level'] < 70)
        low_risk = sum(1 for p in patterns if p['danger_level'] < 30)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì „ì²´ ìœ„í—˜ë„", f"{total_score}")
        with col2:
            st.metric("ê³ ìœ„í—˜ íŒ¨í„´", f"{high_risk}ê°œ")
        with col3:
            st.metric("ì¤‘ìœ„í—˜ íŒ¨í„´", f"{medium_risk}ê°œ")
        with col4:
            st.metric("ì €ìœ„í—˜ íŒ¨í„´", f"{low_risk}ê°œ")

        # ìœ„í—˜ë„ë³„ ê·¸ë£¹í™”
        grouped_patterns = {
            'high': [],
            'medium': [],
            'low': []
        }
        
        for pattern in patterns:
            if pattern['danger_level'] >= 70:
                grouped_patterns['high'].append(pattern)
            elif pattern['danger_level'] >= 30:
                grouped_patterns['medium'].append(pattern)
            else:
                grouped_patterns['low'].append(pattern)

        # ê° ìœ„í—˜ë„ ê·¸ë£¹ë³„ë¡œ í‘œì‹œ
        severity_info = [
            ('high', 'ğŸš¨ ê³ ìœ„í—˜ í•­ëª©', "#FF5252"),
            ('medium', 'âš ï¸ ì£¼ì˜ í•­ëª©', "#FFD700"),
            ('low', 'âœ… ì•ˆì „ í•­ëª©', "#00E676")
        ]

        for severity, title, border_color in severity_info:
            patterns_by_severity = grouped_patterns[severity]
            if not patterns_by_severity:
                continue

            st.markdown(f"""
                <div style='background-color: #2D2D2D; padding: 15px; border-radius: 10px; margin: 15px 0;'>
                    <h3 style='color: {border_color};'>{title} ({len(patterns_by_severity)}ê°œ)</h3>
                </div>
            """, unsafe_allow_html=True)

            # ìœ ì‚¬ íŒ¨í„´ ê·¸ë£¹í™”
            similar_groups = {}
            used_patterns = set()

            for i, pattern in enumerate(patterns_by_severity):
                if i in used_patterns:
                    continue

                similar_group = []
                base_text = pattern.get('text', '')
                base_pattern = pattern.get('pattern', '')

                for j, other_pattern in enumerate(patterns_by_severity[i+1:], i+1):
                    if j in used_patterns:
                        continue

                    other_text = other_pattern.get('text', '')
                    other_pattern_text = other_pattern.get('pattern', '')

                    # ìœ ì‚¬ë„ ê²€ì‚¬
                    text_similarity = difflib.SequenceMatcher(None, base_text, other_text).ratio()
                    pattern_similarity = difflib.SequenceMatcher(None, base_pattern, other_pattern_text).ratio()

                    if text_similarity > 0.8 or pattern_similarity > 0.8:
                        similar_group.append(other_pattern)
                        used_patterns.add(j)

                if similar_group:
                    similar_groups[i] = [pattern] + similar_group
                elif i not in used_patterns:
                    similar_groups[i] = [pattern]

            # ê·¸ë£¹ë³„ë¡œ í‘œì‹œ
            for group_patterns in similar_groups.values():
                main_pattern = group_patterns[0]
                match_percentage = int(main_pattern['match_score'] * 100)

                with st.container():
                    # ë©”ì¸ íŒ¨í„´ í‘œì‹œ
                    cols = st.columns([2, 1, 1])
                    with cols[0]:
                        st.markdown(f"<p style='color:#FFFFFF;'><strong>ìœ„í—˜ë„:</strong> <span style='color:{border_color}; font-weight:bold;'>{main_pattern['danger_level']}</span></p>", unsafe_allow_html=True)
                    with cols[1]:
                        st.markdown(f"<p style='color:#FFFFFF;'><strong>ì¼ì¹˜ìœ¨:</strong> {match_percentage}%</p>", unsafe_allow_html=True)
                    with cols[2]:
                        if len(group_patterns) > 1:
                            st.markdown(f"<p style='color:#FFFFFF;'><strong>ìœ ì‚¬ íŒ¨í„´:</strong> {len(group_patterns)-1}ê°œ</p>", unsafe_allow_html=True)

                    # ì›ë³¸ í…ìŠ¤íŠ¸ì™€ í•˜ì´ë¼ì´íŠ¸
                    st.markdown("<div style='font-weight:bold; margin-top: 10px; color: #FFFFFF;'>ë°œê²¬ëœ í…ìŠ¤íŠ¸:</div>", unsafe_allow_html=True)
                    try:
                        highlighted_text = highlight_pattern_in_text(main_pattern['text'], main_pattern['pattern'])
                        st.markdown(f"""
                            <div style='white-space: pre-wrap; font-family: "Noto Sans KR", sans-serif; 
                                    background-color: #333333; padding: 10px; border-radius: 5px; 
                                    color: #FFFFFF; margin-bottom: 10px;'>
                                {highlighted_text}
                            </div>
                        """, unsafe_allow_html=True)
                    except:
                        st.markdown(f"<div style='background-color: #333333; padding: 10px; border-radius: 5px; color: #FFFFFF;'>{html.escape(str(main_pattern.get('text', '')))}</div>", unsafe_allow_html=True)

                    # ìœ ì‚¬ íŒ¨í„´ í‘œì‹œ
                    if len(group_patterns) > 1:
                        with st.expander(f"ìœ ì‚¬í•œ íŒ¨í„´ {len(group_patterns)-1}ê°œ ë³´ê¸°"):
                            for similar in group_patterns[1:]:
                                try:
                                    highlighted_similar = highlight_pattern_in_text(similar['text'], similar['pattern'])
                                    st.markdown(f"""
                                        <div style='background-color: #2D2D2D; padding: 10px; 
                                                border-radius: 5px; margin: 5px 0;'>
                                            <div style='color: #E0E0E0;'>{highlighted_similar}</div>
                                            <p style='color: #888888; font-size: 0.9em;'>
                                                ì¼ì¹˜ìœ¨: {int(similar['match_score'] * 100)}%
                                            </p>
                                        </div>
                                    """, unsafe_allow_html=True)
                                except:
                                    st.markdown(f"<div style='background-color: #2D2D2D; padding: 10px; border-radius: 5px; margin: 5px 0;'>{html.escape(str(similar.get('text', '')))}</div>", unsafe_allow_html=True)

                    # ë¶„ì„ ì •ë³´
                    st.markdown("<div style='font-weight:bold; margin-top: 10px; color: #FFFFFF;'>ë¶„ì„:</div>", unsafe_allow_html=True)
                    st.markdown(f"""
                        <div style='background-color: rgba{tuple(int(border_color[i:i+2], 16) for i in (1, 3, 5))}, 0.1); 
                                padding: 10px; border-radius: 5px; color: #FFFFFF;'>
                            {html.escape(str(main_pattern.get('analysis', '')))}
                        </div>
                    """, unsafe_allow_html=True)

                    # ì°¸ê³  ìë£Œ ë° ì¸ë„¤ì¼
                    if main_pattern.get("url"):
                        with st.container():
                            if 'thumbnail' in main_pattern:
                                try:
                                    st.image(main_pattern['thumbnail'], width=200)
                                except:
                                    pass
                            st.markdown(f"""
                                <p><strong>ğŸ”— <a href='{html.escape(main_pattern["url"])}' 
                                   target='_blank' style='color:{border_color};'>ì°¸ê³  ìë£Œ</a></strong></p>
                            """, unsafe_allow_html=True)

                    st.markdown("<hr style='border: none; height: 1px; background-color: #555555; margin: 20px 0;'>", unsafe_allow_html=True)

    except Exception as e:
        st.error(f"ê²°ê³¼ í‘œì‹œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

def main():
    st.markdown('<h1 class="main-title">StringAnalysis</h1>', unsafe_allow_html=True)
    st.markdown("""
    > ğŸ’¡ ì…ë ¥ëœ ë¬¸ì¥ì„ ë¶„ì„í•˜ê³  ì ìˆ˜í™”í•˜ì—¬ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.
    """)

    # ë°ì´í„° ë¡œë“œ ë° ê²€ì¦
    try:
        data = load_sheet_data()
        if not data:
            st.error("íŒ¨í„´ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return
            
        if not isinstance(data, list) or not data:
            st.error("íŒ¨í„´ ë°ì´í„° í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return
            
        # ë°ì´í„° êµ¬ì¡° ê²€ì¦
        required_fields = ['text', 'output', 'dangerlevel']
        if not all(isinstance(item, dict) and all(field in item for field in required_fields) for item in data):
            st.error("íŒ¨í„´ ë°ì´í„°ì— í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return
            
        # íƒ­ ìƒì„±
        tab1, tab2, tab3 = st.tabs(["ğŸ” ë¬¸ì¥ ë¶„ì„", "âœï¸ íŒ¨í„´ ë“±ë¡", "ğŸ“ ë§ì¶¤ë²• ê·œì¹™ ê´€ë¦¬"])

        with tab1:
            analysis_type = st.radio(
                "ë¶„ì„ ìœ í˜• ì„ íƒ:",
                ["í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥", "íŒŒì¼/í´ë” ì—…ë¡œë“œ"],
                horizontal=True
            )
            
            if analysis_type == "í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥":
                col1, col2 = st.columns([3, 1])
                with col1:
                    input_text = st.text_area(
                        "ë¶„ì„í•  ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”:",
                        placeholder="ë¶„ì„í•˜ê³  ì‹¶ì€ ë¬¸ì¥ì„ ì…ë ¥í•´ì£¼ì„¸ìš”...",
                        height=100
                    )
                with col2:
                    st.write("")
                    st.write("")
                    analyze_button = st.button("ğŸ” ìœ„í—˜ë„ ë¶„ì„", use_container_width=True, key="analyze")
                
                if analyze_button and input_text:
                    with st.spinner('ğŸ”„ ë¬¸ì¥ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                        try:
                            # ë§ì¶¤ë²• ê²€ì‚¬ì™€ íŒ¨í„´ ë¶„ì„ í†µí•© ìˆ˜í–‰
                            analysis_result = analyze_text_with_spelling(input_text, data)
                            
                            # ë§ì¶¤ë²• ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                            display_spelling_analysis(analysis_result['spelling'])
                            
                            # íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼ í‘œì‹œ
                            found_patterns = analysis_result['patterns']
                            if found_patterns:
                                total_score = calculate_danger_score(found_patterns)
                                st.success(f"ğŸ¯ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! {len(found_patterns)}ê°œì˜ íŒ¨í„´ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                display_analysis_results(found_patterns, total_score)
                            else:
                                st.info("ğŸ‘€ íŠ¹ë³„í•œ ìœ„í—˜ íŒ¨í„´ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                                
                        except Exception as e:
                            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            
            else:  # íŒŒì¼/í´ë” ì—…ë¡œë“œ
                st.markdown("""
                    <div style="background-color: #2D2D2D; padding: 10px; border-radius: 5px; margin-bottom: 10px;">
                        <h4>ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ì•ˆë‚´</h4>
                        <p>â€¢ ë‹¨ì¼/ë‹¤ì¤‘ íŒŒì¼: CSV, Excel íŒŒì¼ ì§ì ‘ ì—…ë¡œë“œ</p>
                        <p>â€¢ í´ë” ì—…ë¡œë“œ: ì—¬ëŸ¬ íŒŒì¼ì„ ZIPìœ¼ë¡œ ì••ì¶•í•˜ì—¬ ì—…ë¡œë“œ</p>
                        <p>â€¢ ì§€ì› í˜•ì‹: .csv, .xlsx, .xls, .zip</p>
                    </div>
                """, unsafe_allow_html=True)
                
                uploaded_files = st.file_uploader(
                    "íŒŒì¼ ë˜ëŠ” ZIP í´ë” ì—…ë¡œë“œ", 
                    type=['csv', 'xlsx', 'xls', 'zip'],
                    accept_multiple_files=True,
                    help="ì—¬ëŸ¬ íŒŒì¼ì„ í•œ ë²ˆì— ì„ íƒí•˜ê±°ë‚˜, ZIP íŒŒì¼ë¡œ ì••ì¶•í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”."
                )
                
                if uploaded_files:
                    if st.button("ğŸ“‚ íŒŒì¼ ë¶„ì„", use_container_width=True):
                        all_results = []
                        total_patterns = 0
                        
                        progress_text = st.empty()
                        progress_bar = st.progress(0)
                        
                        for idx, file in enumerate(uploaded_files):
                            progress = (idx + 1) / len(uploaded_files)
                            progress_bar.progress(progress)
                            progress_text.text(f"íŒŒì¼ ë¶„ì„ ì¤‘... ({idx + 1}/{len(uploaded_files)}): {file.name}")
                            
                            with st.spinner(f'ğŸ”„ {file.name} ë¶„ì„ ì¤‘...'):
                                analysis_result = analyze_file_contents(file, data)
                                if analysis_result and analysis_result['total_patterns'] > 0:
                                    all_results.extend(analysis_result['results'])
                                    total_patterns += analysis_result['total_patterns']
                        
                        progress_bar.empty()
                        progress_text.empty()
                        
                        if total_patterns > 0:
                            st.success(f"ğŸ¯ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ {total_patterns}ê°œì˜ íŒ¨í„´ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            
                            combined_results = {
                                'total_patterns': total_patterns,
                                'results': sorted(all_results, 
                                               key=lambda x: (x['danger_level'], x['match_score']), 
                                               reverse=True)[:1000]
                            }
                            display_file_analysis_results(combined_results)
                        else:
                            st.info("ğŸ‘€ íŒŒì¼ì—ì„œ ìœ„í—˜ íŒ¨í„´ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        with tab2:
            st.markdown("""
            <div style='background-color: #2D2D2D; padding: 1rem; border-radius: 10px; margin-bottom: 1rem;'>
                <h4>ğŸŒŸ ìƒˆë¡œìš´ íŒ¨í„´ ë“±ë¡</h4>
                <p style='color: #E0E0E0;'>ìƒˆë¡œìš´ ìœ„í—˜ íŒ¨í„´ì„ ë“±ë¡í•´ì£¼ì„¸ìš”.</p>
            </div>
            """, unsafe_allow_html=True)
            
            with st.form("pattern_registration_form", clear_on_submit=True):
                pattern_text = st.text_input("ğŸ·ï¸ íŒ¨í„´:", placeholder="ìœ„í—˜ íŒ¨í„´ì„ ì…ë ¥í•˜ì„¸ìš”")
                analysis_text = st.text_area("ğŸ“ ë¶„ì„:", placeholder="ì´ íŒ¨í„´ì˜ ìœ„í—˜ì„±ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”", height=100)
                danger_level = st.slider("âš ï¸ ìœ„í—˜ë„:", 0, 100, 50)
                url = st.text_input("ğŸ”— ì°¸ê³  URL:", placeholder="ê´€ë ¨ ì°¸ê³  ìë£Œ URL")
                
                col1, col2, col3 = st.columns([1,1,1])
                with col2:
                    submit_button = st.form_submit_button("âœ¨ íŒ¨í„´ ë“±ë¡", use_container_width=True)
                        
            if submit_button:
                if all([pattern_text, analysis_text]):
                    try:
                        worksheet = get_sheet_instance()
                        if worksheet:
                            worksheet.append_row([
                                pattern_text,
                                analysis_text,
                                url,
                                danger_level,
                                datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            ])
                            st.success("âœ… íŒ¨í„´ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.balloons()
                            st.cache_data.clear()
                            st.rerun()
                        else:
                            st.error("ì‹œíŠ¸ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        st.error(f"ğŸ˜¢ íŒ¨í„´ ë“±ë¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                else:
                    st.warning("âš ï¸ íŒ¨í„´ê³¼ ë¶„ì„ ë‚´ìš©ì€ í•„ìˆ˜ì…ë‹ˆë‹¤!")
            
            # ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” í‘œì‹œ
            st.markdown("""
            <div class="database-title">
                ğŸ“Š í˜„ì¬ ë“±ë¡ëœ íŒ¨í„´ ë°ì´í„°ë² ì´ìŠ¤
            </div>
            """, unsafe_allow_html=True)
            
            if data:
                df = pd.DataFrame(data)
                
                column_mapping = {
                    'text': 'íŒ¨í„´',
                    'output': 'ë¶„ì„',
                    'url': 'ì°¸ê³  URL',
                    'dangerlevel': 'ìœ„í—˜ë„',
                    'timestamp': 'ë“±ë¡ì¼ì‹œ'
                }
                
                for old_col, new_col in column_mapping.items():
                    if old_col in df.columns:
                        df = df.rename(columns={old_col: new_col})
                
                search_term = st.text_input("ğŸ” íŒ¨í„´ ê²€ìƒ‰:", placeholder="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
                if search_term:
                    pattern_mask = df['íŒ¨í„´'].astype(str).str.contains(search_term, case=False, na=False)
                    analysis_mask = df['ë¶„ì„'].astype(str).str.contains(search_term, case=False, na=False)
                    df = df[pattern_mask | analysis_mask]
                
                if 'ìœ„í—˜ë„' in df.columns:
                    col1, col2 = st.columns(2)
                    with col1:
                        min_danger = st.number_input("ìµœì†Œ ìœ„í—˜ë„:", min_value=0, max_value=100, value=0)
                    with col2:
                        max_danger = st.number_input("ìµœëŒ€ ìœ„í—˜ë„:", min_value=0, max_value=100, value=100)
                    
                    df['ìœ„í—˜ë„'] = pd.to_numeric(df['ìœ„í—˜ë„'], errors='coerce')
                    df = df[(df['ìœ„í—˜ë„'] >= min_danger) & (df['ìœ„í—˜ë„'] <= max_danger)]
                
                st.dataframe(
                    df,
                    use_container_width=True,
                    hide_index=True,
                    height=400
                )
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ì´ íŒ¨í„´ ìˆ˜", len(df))
                if 'ìœ„í—˜ë„' in df.columns:
                    with col2:
                        st.metric("í‰ê·  ìœ„í—˜ë„", f"{df['ìœ„í—˜ë„'].mean():.1f}")
                    with col3:
                        st.metric("ê³ ìœ„í—˜ íŒ¨í„´ ìˆ˜", len(df[df['ìœ„í—˜ë„'] >= 70]))
            else:
                st.info("ë“±ë¡ëœ íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤.")

        with tab3:
            st.markdown("""
                <div style='background-color: #2D2D2D; padding: 1rem; border-radius: 10px; margin-bottom: 1rem;'>
                    <h4>ğŸ“ ë§ì¶¤ë²• ê·œì¹™ ê´€ë¦¬</h4>
                    <p style='color: #E0E0E0;'>ë§ì¶¤ë²• ê²€ì‚¬ì— ì‚¬ìš©ë  ê·œì¹™ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.</p>
                </div>
            """, unsafe_allow_html=True)
            
            with st.form("spelling_rule_form", clear_on_submit=True):
                wrong_text = st.text_input("âŒ ì˜¤ë¥˜ í‘œí˜„:", placeholder="ìˆ˜ì •ì´ í•„ìš”í•œ í‘œí˜„ì„ ì…ë ¥í•˜ì„¸ìš”")
                correct_text = st.text_input("âœ… ì˜¬ë°”ë¥¸ í‘œí˜„:", placeholder="ì˜¬ë°”ë¥¸ í‘œí˜„ì„ ì…ë ¥í•˜ì„¸ìš”")
                
                col1, col2, col3 = st.columns([1,1,1])
                with col2:
                    submit_button = st.form_submit_button("âœ¨ ê·œì¹™ ë“±ë¡", use_container_width=True)
            
            if submit_button:
                if all([wrong_text, correct_text]):
                    try:
                        worksheet = get_sheet_instance()
                        if worksheet:
                            try:
                                checker_sheet = worksheet.worksheet('checker')
                            except:
                                checker_sheet = worksheet.add_worksheet('checker', 1000, 2)
                                checker_sheet.update('A1:B1', [['ì˜¤ë¥˜', 'ìˆ˜ì •']])
                            
                            checker_sheet.append_row([wrong_text, correct_text])
                            st.success("âœ… ë§ì¶¤ë²• ê·œì¹™ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.balloons()
                            st.cache_data.clear()
                            st.rerun()
                        else:
                            st.error("ì‹œíŠ¸ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        st.error(f"ğŸ˜¢ ê·œì¹™ ë“±ë¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                else:
                    st.warning("âš ï¸ ì˜¤ë¥˜ í‘œí˜„ê³¼ ì˜¬ë°”ë¥¸ í‘œí˜„ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            
            # í˜„ì¬ ë“±ë¡ëœ ê·œì¹™ í‘œì‹œ
            st.markdown("""
            <div class="database-title">
                ğŸ“Š í˜„ì¬ ë“±ë¡ëœ ë§ì¶¤ë²• ê·œì¹™
            </div>
            """, unsafe_allow_html=True)
            
            try:
                checker = SheetBasedSpellChecker()
                rules = checker.rules
                
                if rules:
                    df = pd.DataFrame(list(rules.items()), columns=['ì˜¤ë¥˜ í‘œí˜„', 'ì˜¬ë°”ë¥¸ í‘œí˜„'])
                    st.dataframe(
                        df,
                        use_container_width=True,
                        hide_index=True,
                        height=400
                    )
                else:
                    st.info("ë“±ë¡ëœ ë§ì¶¤ë²• ê·œì¹™ì´ ì—†ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                st.error(f"ê·œì¹™ ëª©ë¡ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                
    except Exception as e:
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        st.error("ìƒì„¸ ì˜¤ë¥˜:", exception=True)
        return

if __name__ == "__main__":
    main()