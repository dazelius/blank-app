import streamlit as st
import pandas as pd
import json
import time
from datetime import datetime
import io
import os
import base64
from openai import OpenAI
import traceback
from difflib import SequenceMatcher
from konlpy.tag import Okt
import numpy as np

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Excel ë‹¤êµ­ì–´ ë²ˆì—­ê¸°",
    page_icon="ğŸŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ìŠ¤íƒ€ì¼ ì ìš©
st.markdown("""
    <style>
    .stButton>button {
        width: 100%;
        height: 50px;
        margin-top: 20px;
    }
    .reportview-container {
        background-color: #f0f2f6;
    }
    .css-1d391kg {
        padding: 1rem;
    }
    .stProgress > div > div > div > div {
        background-color: #00cc00;
    }
    div[data-baseweb="notification"] {
        display: none;
    }
    </style>
""", unsafe_allow_html=True)

class KoreanTextSimilarity:
    def __init__(self):
        self.okt = Okt()
        
    def preprocess_text(self, text):
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬: í˜•íƒœì†Œ ë¶„ì„ ë° ì •ê·œí™”"""
        # í˜•íƒœì†Œ ë¶„ì„
        morphs = self.okt.morphs(text, stem=True)
        # ê³µë°± ì œê±° ë° ì†Œë¬¸ì ë³€í™˜
        normalized = [m.strip().lower() for m in morphs if m.strip()]
        return normalized
    
    def calculate_similarity(self, text1, text2):
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        # ê¸°ë³¸ ë¬¸ìì—´ ìœ ì‚¬ë„
        base_similarity = SequenceMatcher(None, text1, text2).ratio()
        
        # í˜•íƒœì†Œ ê¸°ë°˜ ìœ ì‚¬ë„
        processed1 = self.preprocess_text(text1)
        processed2 = self.preprocess_text(text2)
        
        # ê³µí†µ í˜•íƒœì†Œ ë¹„ìœ¨ ê³„ì‚°
        common_morphs = set(processed1) & set(processed2)
        total_morphs = set(processed1) | set(processed2)
        morph_similarity = len(common_morphs) / len(total_morphs) if total_morphs else 0
        
        # í˜•íƒœì†Œ ì‹œí€€ìŠ¤ ìœ ì‚¬ë„
        seq_similarity = SequenceMatcher(None, ' '.join(processed1), ' '.join(processed2)).ratio()
        
        # ìµœì¢… ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ì¹˜ ì ìš©)
        final_similarity = (base_similarity * 0.3 + 
                          morph_similarity * 0.4 + 
                          seq_similarity * 0.3)
        
        return final_similarity * 100  # ë°±ë¶„ìœ¨ë¡œ ë³€í™˜
    
    def check_similarity_threshold(self, text1, text2, threshold=50):
        """ì„ê³„ê°’ ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ì‚¬"""
        similarity = self.calculate_similarity(text1, text2)
        return similarity >= threshold, similarity

def filter_similar_texts(search_text, text_list, threshold=50):
    """ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ í•„í„°ë§"""
    similarity_checker = KoreanTextSimilarity()
    similar_texts = []
    
    for text in text_list:
        is_similar, similarity = similarity_checker.check_similarity_threshold(
            search_text, text, threshold
        )
        if is_similar:
            similar_texts.append({
                'text': text,
                'similarity': similarity
            })
    
    # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    similar_texts.sort(key=lambda x: x['similarity'], reverse=True)
    return similar_texts

def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'api_key' not in st.session_state:
        try:
            # secrets.toml íŒŒì¼ì—ì„œ API í‚¤ ì½ê¸° ì‹œë„
            st.session_state.api_key = st.secrets.get("OPENAI_API_KEY", "")
        except Exception as e:
            # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ì½ê¸° ì‹œë„
            st.session_state.api_key = os.getenv("OPENAI_API_KEY", "")
            
        # API í‚¤ ê²€ì¦
        if not st.session_state.api_key:
            st.error("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.info("""
            ğŸ’¡ ë‹¤ìŒ ë‘ ê°€ì§€ ë°©ë²• ì¤‘ í•˜ë‚˜ë¡œ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”:
            1. `.streamlit/secrets.toml` íŒŒì¼ì— ì¶”ê°€:
               ```toml
               OPENAI_API_KEY = "your-api-key-here"
               ```
            2. í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •:
               ```bash
               export OPENAI_API_KEY="your-api-key-here"
               ```
            """)
            st.stop()

def handle_error(func):
    """ì—ëŸ¬ ì²˜ë¦¬ ë°ì½”ë ˆì´í„°"""
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            error_details = traceback.format_exc()
            print(f"Error in {func.__name__}: {error_details}")
            return [f"ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"] * len(args[0]) if args else None
    return wrapper

@handle_error
def translate_batch(texts, target_language, client):
    """ë°°ì¹˜ ë²ˆì—­ í•¨ìˆ˜"""
    language_contexts = {
        'en_US': {
            'name': 'English',
            'rules': ['Keep UI terms consistent', 'Use gaming industry standard terms']
        },
        'ja_JP': {
            'name': 'æ—¥æœ¬èª',
            'rules': ['Use proper gaming terminology', 'Maintain correct keigo level']
        },
        'zh_CN': {
            'name': 'ç®€ä½“ä¸­æ–‡',
            'rules': ['Use simplified Chinese characters', 'Follow mainland China gaming terms']
        },
        'zh_TW': {
            'name': 'ç¹é«”ä¸­æ–‡',
            'rules': ['Use traditional Chinese characters', 'Follow Taiwan gaming terms']
        },
        'pt_BR': {
            'name': 'PortuguÃªs',
            'rules': [
                'Use Brazilian Portuguese conventions',
                'Follow gaming industry standard terms in Portuguese',
                'Maintain consistent formality level'
            ]
        },
        'es_ES': {
            'name': 'EspaÃ±ol',
            'rules': [
                'Use neutral Spanish terms when possible',
                'Follow gaming industry standard terms in Spanish',
                'Maintain consistent formality level'
            ]
        }
    }

    context = language_contexts.get(target_language, {})
    
    prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ ê²Œì„ í˜„ì§€í™” ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ í…ìŠ¤íŠ¸ë“¤ì„ {context.get('name', target_language)}ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.

ë²ˆì—­ ê·œì¹™:
1. ê²Œì„ UI/UX ìš©ì–´ì˜ ì¼ê´€ì„±ì„ ì—„ê²©íˆ ìœ ì§€í•˜ì„¸ìš”
2. ì›ë¬¸ì˜ ì˜ë¯¸ë¥¼ ì •í™•í•˜ê²Œ ìœ ì§€í•˜ì„¸ìš”
3. ê²Œì„ ì‚°ì—… í‘œì¤€ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
4. ê° ë¬¸ì¥ì„ ë…ë¦½ì ìœ¼ë¡œ ë²ˆì—­í•˜ì„¸ìš”
5. ë¬¸í™”ì  ë§¥ë½ì„ ê³ ë ¤í•˜ì„¸ìš”
{' '.join(context.get('rules', []))}

ë²ˆì—­í•  í…ìŠ¤íŠ¸ ëª©ë¡:
{json.dumps(texts, ensure_ascii=False)}

JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
"""

    for attempt in range(3):  # ìµœëŒ€ 3ë²ˆ ì¬ì‹œë„
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an expert game localization translator."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2000,
                temperature=0.3
            )

            content = response.choices[0].message.content.strip()
            
            # JSON í˜•ì‹ ì¶”ì¶œ ë° ê²€ì¦
            start_idx = content.find('[')
            end_idx = content.rfind(']') + 1
            
            if start_idx == -1 or end_idx == 0:
                raise ValueError("JSON í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤")
                
            json_content = content[start_idx:end_idx]
            translations = json.loads(json_content)
            
            if len(translations) != len(texts):
                raise ValueError(f"ë²ˆì—­ ê²°ê³¼ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: ì…ë ¥ {len(texts)}ê°œ, ì¶œë ¥ {len(translations)}ê°œ")
                
            return translations
            
        except Exception as e:
            if attempt == 2:  # ë§ˆì§€ë§‰ ì‹œë„ì—ì„œ ì‹¤íŒ¨
                print(f"Translation error after 3 attempts: {str(e)}")
                return [f"ë²ˆì—­ ì‹¤íŒ¨: {str(e)}"] * len(texts)
            time.sleep(2)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°

@handle_error
def process_excel(df, text_column, progress_bar, status_text):
    """ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬"""
    try:
        client = OpenAI(api_key=st.session_state.api_key)
        
        # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ì´ˆê¸°í™”
        result_df = pd.DataFrame(index=df.index)
        result_df['ì›ë¬¸'] = df[text_column]
        
        # ë¹ˆ ê°’ ì²˜ë¦¬
        df[text_column] = df[text_column].fillna('')
        
        # ë²ˆì—­í•  í…ìŠ¤íŠ¸ ì¤€ë¹„ (ì¸ë±ìŠ¤ ìœ ì§€)
        texts_with_index = [(idx, text) for idx, text in enumerate(df[text_column]) if text.strip()]
        if not texts_with_index:
            st.warning("ë²ˆì—­í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return df
            
        indices, texts = zip(*texts_with_index)
        
        total_texts = len(texts)
        batch_size = 20
        
        # ë²ˆì—­ ì–¸ì–´ ì„¤ì •
        languages = {
            'English': 'en_US',
            'Japanese': 'ja_JP',
            'Chinese(Simplified)': 'zh_CN',
            'Chinese(Traditional)': 'zh_TW',
            'Portuguese': 'pt_BR',
            'Spanish': 'es_ES'
        }

        for i, (lang_name, lang_code) in enumerate(languages.items()):
            translations_dict = {}
            
            for j in range(0, total_texts, batch_size):
                batch_texts = list(texts[j:j+batch_size])
                batch_indices = list(indices[j:j+batch_size])
                
                # ì§„í–‰ë¥  ê³„ì‚°
                progress = (j + (i * total_texts)) / (total_texts * len(languages))
                progress_bar.progress(min(0.99, progress))  # 1.0ì—ì„œ ì˜¤ë¥˜ ë°©ì§€
                status_text.text(f"ë²ˆì—­ ì¤‘: {lang_name} - {j}/{total_texts}")
                
                # ë°°ì¹˜ ë²ˆì—­
                batch_translations = translate_batch(batch_texts, lang_code, client)
                
                # ì¸ë±ìŠ¤ì™€ ë²ˆì—­ ê²°ê³¼ ë§¤í•‘
                for idx, trans in zip(batch_indices, batch_translations):
                    translations_dict[idx] = trans
                
                time.sleep(0.5)  # API ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€
            
            # ì „ì²´ ë°ì´í„°í”„ë ˆì„ í¬ê¸°ì— ë§ê²Œ ë²ˆì—­ ê²°ê³¼ ë°°ì—´ ìƒì„±
            translations_array = [""] * len(df)
            for idx, trans in translations_dict.items():
                translations_array[idx] = trans
            
            result_df[lang_name] = translations_array
        
        progress_bar.progress(1.0)
        return result_df
        
    except Exception as e:
        st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

def get_table_download_link(df):
    """ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„±"""
    try:
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False)
        excel_data = output.getvalue()
        b64 = base64.b64encode(excel_data).decode()
        filename = f"translated_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        return f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="{filename}">ğŸ“¥ ë²ˆì—­ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ</a>'
    except Exception as e:
        st.error(f"íŒŒì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

def find_text_column(df):
    """í…ìŠ¤íŠ¸ ì—´ ì°¾ê¸°"""
    for col in df.columns:
        if 'text' in str(col).lower():
            return col
    
    for col in df.columns:
        if any('\u3131' <= c <= '\u318F' or '\uAC00' <= c <= '\uD7A3' for c in str(col)):
            return col
    
    return df.columns[0]

def main():
    st.title("ğŸŒ Excel ë‹¤êµ­ì–´ ë²ˆì—­ê¸°")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    init_session_state()
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.subheader("ğŸ“‹ ì‚¬ìš© ë°©ë²•")
        st.markdown("""
        1. Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”
        2. ë²ˆì—­í•  ì—´ì´ ìë™ìœ¼ë¡œ ì„ íƒë©ë‹ˆë‹¤
        3. ë²ˆì—­ ì‹œì‘ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
        
        ### ğŸŒ ì§€ì› ì–¸ì–´
        - English (en_US)
        - Japanese (ja_JP)
        - Chinese Simplified (zh_CN)
        - Chinese Traditional (zh_TW)
        - Portuguese (pt_BR)
        - Spanish (es_ES)
        """)
    
    # ë©”ì¸ ì˜ì—­
    uploaded_file = st.file_uploader(
        "Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (.xlsx)",
        type=['xlsx']
    )
    
    if uploaded_file:
        try:
            df = pd.read_excel(uploaded_file)
            text_column = find_text_column(df)
            st.info(f"'{text_column}' ì—´ì´ ë²ˆì—­ ëŒ€ìƒìœ¼ë¡œ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€
            search_text = st.text_input("í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ìœ ì‚¬ë„ ê¸°ë°˜)")
            if search_text:
                texts = df[text_column].dropna().tolist()
                similar_texts = filter_similar_texts(search_text, texts)
                
                if similar_texts:
                    st.subheader("ìœ ì‚¬í•œ í…ìŠ¤íŠ¸")
                    for item in similar_texts:
                        st.write(f"- {item['text']} (ìœ ì‚¬ë„: {item['similarity']:.2f}%)")
                else:
                    st.info("ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            
            if st.button("ë²ˆì—­ ì‹œì‘"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                with st.spinner('ë²ˆì—­ ì²˜ë¦¬ ì¤‘...'):
                    result_df = process_excel(
                        df, text_column, progress_bar, status_text
                    )
                    
                    if result_df is not None:
                        st.success("âœ… ë²ˆì—­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
                        # ê²°ê³¼ í‘œì‹œ
                        st.subheader("ë²ˆì—­ ê²°ê³¼")
                        st.dataframe(result_df, height=400)
                        
                        # ë‹¤ìš´ë¡œë“œ ë§í¬
                        download_link = get_table_download_link(result_df)
                        if download_link:
                            st.markdown(download_link, unsafe_allow_html=True)
                        
                        # í†µê³„
                        st.subheader("ğŸ“Š ë²ˆì—­ í†µê³„")
                        col1, col2 = st.columns(2)
                        with col1:
                            total_items = len([x for x in result_df['ì›ë¬¸'] if str(x).strip()])
                            st.metric("ë²ˆì—­ëœ í•­ëª©", total_items)
                        with col2:
                            st.metric("ì§€ì› ì–¸ì–´", "6ê°œ")
                    
        except Exception as e:
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            
    else:
        st.info("ğŸ‘† Excel íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()